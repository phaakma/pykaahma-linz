{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pykaahma-linz","text":"<p>A Pythonic client for accessing and querying datasets from the LINZ Data Service.</p>"},{"location":"#overview","title":"Overview","text":"<p>pykaahma-linz is a Python package that provides a clean, Pythonic interface to the Koordinates geospatial content management system. It allows users to connect to the Koordinates API, retrieve metadata, and query datasets such as vector layers, tables, rasters, and point clouds. As the name indicates, this was written with LINZ (Land Information New Zealand) in mind and simplifies programmatic access to their open geospatial data. </p> <p>Source code and documentation available at Github repo </p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>This is a hobby project and the modules are provided as-is on a best-effort basis and you assume all risk for using it. The author has no affiliation with either Koordinates nor LINZ. As such, the underlying API's and services may change at any time without warning and break these modules. The author is not privvy to any inside knowledge or documentation beyond what is available online or by inspecting the payloads returned by the services.  </p> <p>This project does not cover the full spectrum of the Koordinates API and probably never will. It focuses currently on basic workflows such as connecting using an api key, getting references to datasets and downloading them. The package has not been tested against any other Koordinates deployment and there may be LINZ specific logic buried in the code. </p> <p>The author is happy to take feedback and consider suggestions and code contributions as time allows. Preferred method for feedback is via the Github repository issues page.    </p>"},{"location":"#installation","title":"Installation","text":"<p>Documentation is non-existent at the moment, but here is the basic approach so far. </p> <pre><code>pip install pykaahma-linz\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<ul> <li>Import KServer.  </li> <li>Create a KServer object, passing in an api key.  </li> <li>Get a reference to an item using {kserver}.content.get({layer_id})</li> <li>Perform actions on the item.  </li> </ul> <p>Basic example:  </p> <pre><code>from pykaahma_linz.KServer import KServer\nlinz = KServer(api_key)\nrail_station_layer_id = \"50318\"\nitm = linz.content.get(rail_station_layer_id)\ndata = itm.query()\ndata.head()\n</code></pre>"},{"location":"#tests","title":"Tests","text":"<p>Tests are written using pytest. To run tests using UV:  </p> <pre><code>uv run -m pytest --log-cli-level=INFO\n</code></pre> <p>There is currently very limited test coverage. Any live tests require a \"LINZ_API_KEY\" entry to exist in a .env file in the root project folder.  </p>"},{"location":"development_notes/","title":"Development Notes","text":"<p>These are just general notes for the author to help remember design choices, rabbit holes and how they panned out, etc.  </p>"},{"location":"development_notes/#installation","title":"Installation","text":"<p>When I run <code>uv sync</code> and <code>uv pip install -e .</code> on a new cloned copy, if I have a python environment activated already in my terminal it seems to do odd things sometimes. VS Code sometimes activates automatically depending on settings. And sometimes those settings vary between PowerShell and the standard Command Prompt. So I find it best to ensure I open a separate Command Prompt window with nothing activated, run those initial commands there, and then open up VS Code and any terminal windows. </p> <p>If installing from the whl file using UV, remember to add the package name.</p> <pre><code>uv pip install pykaahma-linz@path/to/packagefile.whl\n</code></pre> <p>If using the code directly rather than installing from PyPi (once it is uploaded to there), run the following to install the package locally in editable mode.</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"development_notes/#development-using-jupyter-notebooks","title":"Development using Jupyter Notebooks","text":"<p>I got the following tips from Cookie Cutter Data Science. Cookie Cutter Data Science </p> <p>Make the project a python package and install it locally. I was using UV, so I ran this command:</p> <pre><code>uv pip install -e .  \n</code></pre> <p>Then, in my notebook, I included this cell first:  </p> <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <p>This allowed me to load my local python package like this:  </p> <pre><code>from k_data_helpers import KServer  \n</code></pre> <p>And it would hot reload any changes I made while developing.</p>"},{"location":"development_notes/#koordinates-api","title":"Koordinates API","text":""},{"location":"development_notes/#export-api","title":"Export API","text":"<p>The export api doesn't appear to have an option for applying a cql_filter or any similar filter. Only extent. The extent appears to have to be a geojson geometry object. Note that this is just the geometry part, not the properties or collection. And it would have to be in WGS84. I might look at ways to handle passing in geometry objects of different types, such as from a geopandas geometry, and behind the scenes just handling that and converting to the corrrect format.  </p> <p>Also, the export API treats the extent as a crop, and so features will be clipped. This may not be desired in all situations, e.g. clipping Property Parcels is not usually a good thing as someone may inadvertantly think that that is the actually parcel geometry, not realising it was clipped. The question is: how to handle this? Just warn the user in documentation and leave it up to them? Apply a buffer and do some post-processing? I'm inclined to do less, let the system supply as it is designed, and educate the user. This does imply the end user needs to do a little bit extra work but I would rather the user explicitly get the output and the module logic not get in the way.  </p> <p>It does appear to allow generating an export of multiple items at once. E.g. you could request several layers in one zipped file geodatabase. Currently, this wrapper only supports one at a time, because I didn't realise at the time you could do multiple, so this would be a good enhancement for the future. The current approach is based off starting with an item and downloading that. So a multi item download would need to be initiated by a higher order class, perhaps the ContentManager?  </p> <p>Need to think about how a user would most likely pass in the parameters for a multi download without constructing the whole list verbosely, but allowing them to do that if they wish.  </p>"},{"location":"development_notes/#notes-on-design-choices","title":"Notes on design choices","text":""},{"location":"development_notes/#owslib","title":"OWSLib","text":"<p>I investigated using the OWSLib python package to download the WFS data, but discovered that it doesn't support the CQL filter keyword option that the LINZ GeoServer provides. OGC filters were still an option, but seem very complex to construct and I believe most users would prefer to use the simpler CQL which is more similar to SQL. So I moved back to using a basic request to the WFS endpoint. The OWSLib package would provide more scope for expansion, but since the intent of this helper library is primarily focused on Koordinates and LINZ in particular, we can afford to be a little more opinionated on our approach, such as not having to support all the WFS versions. I'm not sure if the LINZ WFS endpoint is strictly equivalent with all other Koordinates WFS endpoints. So the implementation at the moment is coded to work with LINZ and might not work in other places.  </p>"},{"location":"reference/","title":"API Reference","text":"<p>KServer.py A class to connect with a Koordinates server.</p> <p>KItem.py A base class to represent an item.</p> <p>KTableItem.py A class to represent a table dataset.</p> <p>KVectorItem.py A class to represent a vector dataset.</p> <p>ContentManager is a class that manages the content of a KServer instance.</p> <p>JobResult.py</p>"},{"location":"reference/#pykaahma_linz.KServer.KServer","title":"<code>KServer</code>","text":"<p>Client for connecting to a Koordinates server.</p> <p>Provides methods for authenticating, accessing content, and making HTTP requests to the Koordinates API. Used as the main entry point for interacting with Koordinates-hosted data.</p> <p>Attributes:</p> Name Type Description <code>_base_url</code> <code>str</code> <p>The base URL of the Koordinates server.</p> <code>_api_version</code> <code>str</code> <p>The API version to use.</p> <code>_content_manager</code> <code>ContentManager or None</code> <p>Cached ContentManager instance.</p> <code>_wfs_manager</code> <code>object or None</code> <p>Cached WFS manager instance (if implemented).</p> <code>_api_key</code> <code>str</code> <p>The API key for authenticating requests.</p> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>class KServer:\n    \"\"\"\n    Client for connecting to a Koordinates server.\n\n    Provides methods for authenticating, accessing content, and making HTTP requests to the Koordinates API.\n    Used as the main entry point for interacting with Koordinates-hosted data.\n\n    Attributes:\n        _base_url (str): The base URL of the Koordinates server.\n        _api_version (str): The API version to use.\n        _content_manager (ContentManager or None): Cached ContentManager instance.\n        _wfs_manager (object or None): Cached WFS manager instance (if implemented).\n        _api_key (str): The API key for authenticating requests.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key,\n        base_url=DEFAULT_BASE_URL,\n        api_version=DEFAULT_API_VERSION,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the KServer instance with the base URL, API version, and API key.\n\n        Parameters:\n            api_key (str): The API key for authenticating with the Koordinates server.\n            base_url (str, optional): The base URL of the Koordinates server. Defaults to 'https://data.linz.govt.nz/'.\n            api_version (str, optional): The API version to use. Defaults to 'v1.x'.\n        \"\"\"\n        self._base_url = base_url\n        self._api_version = api_version\n        self._content_manager = None\n        self._wfs_manager = None\n        self._api_key = api_key\n        if not self._api_key:\n            raise KServerError(\"API key must be provided.\")\n        logger.debug(f\"KServer initialized with base URL: {self._base_url}\")\n\n    @property\n    def _service_url(self) -&gt; str:\n        \"\"\"\n        Returns the service URL for the Koordinates server.\n\n        Returns:\n            str: The full service URL.\n        \"\"\"\n        return f\"{self._base_url}services/\"\n\n    @property\n    def _api_url(self) -&gt; str:\n        \"\"\"\n        Returns the API URL for the Koordinates server.\n\n        Returns:\n            str: The full API URL.\n        \"\"\"\n        return f\"{self._service_url}api/{self._api_version}/\"\n\n    @property\n    def _wfs_url(self) -&gt; str:\n        \"\"\"\n        Returns the WFS URL for the Koordinates server.\n\n        Returns:\n            str: The WFS URL.\n        \"\"\"\n        return f\"{self._service_url}wfs/\"\n\n    @property\n    def content(self) -&gt; ContentManager:\n        \"\"\"\n        Returns the ContentManager instance for this server.\n\n        Returns:\n            ContentManager: The content manager associated with this server.\n        \"\"\"\n        if self._content_manager is None:\n            self._content_manager = ContentManager(self)\n        return self._content_manager\n\n    def get(self, url: str, params: dict = None) -&gt; dict:\n        \"\"\"\n        Makes a synchronous GET request to the specified URL with the provided parameters.\n        Injects the API key into the request headers.\n\n        Parameters:\n            url (str): The URL to send the GET request to.\n            params (dict, optional): Query parameters to include in the request. Defaults to None.\n\n        Returns:\n            dict: The JSON response from the server.\n\n        Raises:\n            KServerBadRequestError: If the request fails with a 400 status code.\n            KServerError: For other HTTP errors or request exceptions.\n        \"\"\"\n        headers = {\"Authorization\": f\"key {self._api_key}\"}\n        logger.debug(f\"Making kserver GET request to {url} with params {params}\")\n        try:\n            response = httpx.get(url, headers=headers, params=params, timeout=30)\n        except httpx.RequestError as exc:\n            logger.error(f\"An error occurred while requesting {exc.request.url!r}.\")\n            raise KServerError(str(exc)) from exc\n\n        if response.status_code == 400:\n            raise KServerBadRequestError(response.text)\n        response.raise_for_status()\n        return response.json()\n\n    async def async_get(self, url: str, params: dict = None) -&gt; dict:\n        \"\"\"\n        Makes an asynchronous GET request to the specified URL with the provided parameters.\n        Injects the API key into the request headers.\n\n        Parameters:\n            url (str): The URL to send the GET request to.\n            params (dict, optional): Query parameters to include in the request. Defaults to None.\n\n        Returns:\n            dict: The JSON response from the server.\n\n        Raises:\n            KServerBadRequestError: If the request fails with a 400 status code.\n            KServerError: For other HTTP errors or request exceptions.\n        \"\"\"\n        headers = {\"Authorization\": f\"key {self._api_key}\"}\n        logger.debug(f\"Making async kserver GET request to {url} with params {params}\")\n        async with httpx.AsyncClient(timeout=30) as client:\n            try:\n                response = await client.get(url, headers=headers, params=params)\n            except httpx.RequestError as exc:\n                logger.error(f\"An error occurred while requesting {exc.request.url!r}.\")\n                raise KServerError(str(exc)) from exc\n\n            if response.status_code == 400:\n                raise KServerBadRequestError(response.text)\n            response.raise_for_status()\n            return response.json()\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Resets the KServer instance, forcing the content manager and WFS manager\n        to reinitialize the next time they are accessed. This is useful if the API key\n        or other configurations change.\n\n        Returns:\n            None\n        \"\"\"\n        self._content_manager = None\n        self._wfs_manager = None\n        logger.info(\"KServer instance reset.\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Returns a string representation of the KServer instance.\n\n        Returns:\n            str: String representation of the KServer instance.\n        \"\"\"\n        return f\"KServer(base_url={self._base_url}, api_version={self._api_version})\"\n</code></pre>"},{"location":"reference/#pykaahma_linz.KServer.KServer.content","title":"<code>content</code>  <code>property</code>","text":"<p>Returns the ContentManager instance for this server.</p> <p>Returns:</p> Name Type Description <code>ContentManager</code> <code>ContentManager</code> <p>The content manager associated with this server.</p>"},{"location":"reference/#pykaahma_linz.KServer.KServer.__init__","title":"<code>__init__(api_key, base_url=DEFAULT_BASE_URL, api_version=DEFAULT_API_VERSION)</code>","text":"<p>Initializes the KServer instance with the base URL, API version, and API key.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>The API key for authenticating with the Koordinates server.</p> required <code>base_url</code> <code>str</code> <p>The base URL of the Koordinates server. Defaults to 'https://data.linz.govt.nz/'.</p> <code>DEFAULT_BASE_URL</code> <code>api_version</code> <code>str</code> <p>The API version to use. Defaults to 'v1.x'.</p> <code>DEFAULT_API_VERSION</code> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>def __init__(\n    self,\n    api_key,\n    base_url=DEFAULT_BASE_URL,\n    api_version=DEFAULT_API_VERSION,\n) -&gt; None:\n    \"\"\"\n    Initializes the KServer instance with the base URL, API version, and API key.\n\n    Parameters:\n        api_key (str): The API key for authenticating with the Koordinates server.\n        base_url (str, optional): The base URL of the Koordinates server. Defaults to 'https://data.linz.govt.nz/'.\n        api_version (str, optional): The API version to use. Defaults to 'v1.x'.\n    \"\"\"\n    self._base_url = base_url\n    self._api_version = api_version\n    self._content_manager = None\n    self._wfs_manager = None\n    self._api_key = api_key\n    if not self._api_key:\n        raise KServerError(\"API key must be provided.\")\n    logger.debug(f\"KServer initialized with base URL: {self._base_url}\")\n</code></pre>"},{"location":"reference/#pykaahma_linz.KServer.KServer.__repr__","title":"<code>__repr__()</code>","text":"<p>Returns a string representation of the KServer instance.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String representation of the KServer instance.</p> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the KServer instance.\n\n    Returns:\n        str: String representation of the KServer instance.\n    \"\"\"\n    return f\"KServer(base_url={self._base_url}, api_version={self._api_version})\"\n</code></pre>"},{"location":"reference/#pykaahma_linz.KServer.KServer.async_get","title":"<code>async_get(url, params=None)</code>  <code>async</code>","text":"<p>Makes an asynchronous GET request to the specified URL with the provided parameters. Injects the API key into the request headers.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>params</code> <code>dict</code> <p>Query parameters to include in the request. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The JSON response from the server.</p> <p>Raises:</p> Type Description <code>KServerBadRequestError</code> <p>If the request fails with a 400 status code.</p> <code>KServerError</code> <p>For other HTTP errors or request exceptions.</p> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>async def async_get(self, url: str, params: dict = None) -&gt; dict:\n    \"\"\"\n    Makes an asynchronous GET request to the specified URL with the provided parameters.\n    Injects the API key into the request headers.\n\n    Parameters:\n        url (str): The URL to send the GET request to.\n        params (dict, optional): Query parameters to include in the request. Defaults to None.\n\n    Returns:\n        dict: The JSON response from the server.\n\n    Raises:\n        KServerBadRequestError: If the request fails with a 400 status code.\n        KServerError: For other HTTP errors or request exceptions.\n    \"\"\"\n    headers = {\"Authorization\": f\"key {self._api_key}\"}\n    logger.debug(f\"Making async kserver GET request to {url} with params {params}\")\n    async with httpx.AsyncClient(timeout=30) as client:\n        try:\n            response = await client.get(url, headers=headers, params=params)\n        except httpx.RequestError as exc:\n            logger.error(f\"An error occurred while requesting {exc.request.url!r}.\")\n            raise KServerError(str(exc)) from exc\n\n        if response.status_code == 400:\n            raise KServerBadRequestError(response.text)\n        response.raise_for_status()\n        return response.json()\n</code></pre>"},{"location":"reference/#pykaahma_linz.KServer.KServer.get","title":"<code>get(url, params=None)</code>","text":"<p>Makes a synchronous GET request to the specified URL with the provided parameters. Injects the API key into the request headers.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>params</code> <code>dict</code> <p>Query parameters to include in the request. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The JSON response from the server.</p> <p>Raises:</p> Type Description <code>KServerBadRequestError</code> <p>If the request fails with a 400 status code.</p> <code>KServerError</code> <p>For other HTTP errors or request exceptions.</p> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>def get(self, url: str, params: dict = None) -&gt; dict:\n    \"\"\"\n    Makes a synchronous GET request to the specified URL with the provided parameters.\n    Injects the API key into the request headers.\n\n    Parameters:\n        url (str): The URL to send the GET request to.\n        params (dict, optional): Query parameters to include in the request. Defaults to None.\n\n    Returns:\n        dict: The JSON response from the server.\n\n    Raises:\n        KServerBadRequestError: If the request fails with a 400 status code.\n        KServerError: For other HTTP errors or request exceptions.\n    \"\"\"\n    headers = {\"Authorization\": f\"key {self._api_key}\"}\n    logger.debug(f\"Making kserver GET request to {url} with params {params}\")\n    try:\n        response = httpx.get(url, headers=headers, params=params, timeout=30)\n    except httpx.RequestError as exc:\n        logger.error(f\"An error occurred while requesting {exc.request.url!r}.\")\n        raise KServerError(str(exc)) from exc\n\n    if response.status_code == 400:\n        raise KServerBadRequestError(response.text)\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"reference/#pykaahma_linz.KServer.KServer.reset","title":"<code>reset()</code>","text":"<p>Resets the KServer instance, forcing the content manager and WFS manager to reinitialize the next time they are accessed. This is useful if the API key or other configurations change.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\KServer.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Resets the KServer instance, forcing the content manager and WFS manager\n    to reinitialize the next time they are accessed. This is useful if the API key\n    or other configurations change.\n\n    Returns:\n        None\n    \"\"\"\n    self._content_manager = None\n    self._wfs_manager = None\n    logger.info(\"KServer instance reset.\")\n</code></pre>"},{"location":"reference/#pykaahma_linz.KItem.KItem","title":"<code>KItem</code>","text":"<p>Base class for representing an item in the Koordinates system.</p> <p>This class provides a structure for items that can be extended by specific item types. It stores basic metadata and provides dynamic attribute access.</p> <p>Attributes:</p> Name Type Description <code>_kserver</code> <code>KServer</code> <p>The KServer instance this item belongs to.</p> <code>_raw_json</code> <code>dict</code> <p>The raw JSON dictionary representing the item.</p> <code>id</code> <code>str</code> <p>The unique identifier of the item.</p> <code>url</code> <code>str</code> <p>The URL of the item.</p> <code>type</code> <code>str</code> <p>The type of the item (e.g., 'layer', 'table').</p> <code>kind</code> <code>str</code> <p>The kind of the item (e.g., 'vector', 'table').</p> <code>title</code> <code>str</code> <p>The title of the item.</p> <code>description</code> <code>str</code> <p>The description of the item.</p> <code>_jobs</code> <code>list</code> <p>List of JobResult objects associated with this item.</p> Source code in <code>src\\pykaahma_linz\\KItem.py</code> <pre><code>class KItem:\n    \"\"\"\n    Base class for representing an item in the Koordinates system.\n\n    This class provides a structure for items that can be extended by specific item types.\n    It stores basic metadata and provides dynamic attribute access.\n\n    Attributes:\n        _kserver (KServer): The KServer instance this item belongs to.\n        _raw_json (dict): The raw JSON dictionary representing the item.\n        id (str): The unique identifier of the item.\n        url (str): The URL of the item.\n        type (str): The type of the item (e.g., 'layer', 'table').\n        kind (str): The kind of the item (e.g., 'vector', 'table').\n        title (str): The title of the item.\n        description (str): The description of the item.\n        _jobs (list): List of JobResult objects associated with this item.\n    \"\"\"\n\n    def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n        \"\"\"\n        Initializes the KItem instance from a dictionary returned from the API.\n\n        Parameters:\n            kserver (KServer): The KServer instance that this item belongs to.\n            item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n        Returns:\n            None\n        \"\"\"\n        self._kserver = kserver\n        self._raw_json = item_dict\n        self.id = item_dict.get(\"id\")\n        self.url = item_dict.get(\"url\")\n        self.type = item_dict.get(\"type\")\n        self.kind = item_dict.get(\"kind\")\n        self.title = item_dict.get(\"title\")\n        self.description = item_dict.get(\"description\")\n        self._jobs = []\n\n    def __getattr__(self, item) -&gt; object:\n        \"\"\"\n        Provides dynamic attribute access for the item.\n\n        Parameters:\n            item (str): The name of the attribute to access.\n\n        Returns:\n            The value of the requested attribute, or None if it does not exist.\n        \"\"\"\n        attr = self._raw_json.get(item, None)\n        if attr is None:\n            raise AttributeError(f\"{self.__class__.__name__} has no attribute '{item}'\")\n        return attr\n\n    def __repr__(self) -&gt; str:\n        return f\"KItem(id={self.id}, title={self.title}, type={self.type})\"\n</code></pre>"},{"location":"reference/#pykaahma_linz.KItem.KItem.__getattr__","title":"<code>__getattr__(item)</code>","text":"<p>Provides dynamic attribute access for the item.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>str</code> <p>The name of the attribute to access.</p> required <p>Returns:</p> Type Description <code>object</code> <p>The value of the requested attribute, or None if it does not exist.</p> Source code in <code>src\\pykaahma_linz\\KItem.py</code> <pre><code>def __getattr__(self, item) -&gt; object:\n    \"\"\"\n    Provides dynamic attribute access for the item.\n\n    Parameters:\n        item (str): The name of the attribute to access.\n\n    Returns:\n        The value of the requested attribute, or None if it does not exist.\n    \"\"\"\n    attr = self._raw_json.get(item, None)\n    if attr is None:\n        raise AttributeError(f\"{self.__class__.__name__} has no attribute '{item}'\")\n    return attr\n</code></pre>"},{"location":"reference/#pykaahma_linz.KItem.KItem.__init__","title":"<code>__init__(kserver, item_dict)</code>","text":"<p>Initializes the KItem instance from a dictionary returned from the API.</p> <p>Parameters:</p> Name Type Description Default <code>kserver</code> <code>KServer</code> <p>The KServer instance that this item belongs to.</p> required <code>item_dict</code> <code>dict</code> <p>A dictionary containing the item's details, typically from an API response.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\KItem.py</code> <pre><code>def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n    \"\"\"\n    Initializes the KItem instance from a dictionary returned from the API.\n\n    Parameters:\n        kserver (KServer): The KServer instance that this item belongs to.\n        item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n    Returns:\n        None\n    \"\"\"\n    self._kserver = kserver\n    self._raw_json = item_dict\n    self.id = item_dict.get(\"id\")\n    self.url = item_dict.get(\"url\")\n    self.type = item_dict.get(\"type\")\n    self.kind = item_dict.get(\"kind\")\n    self.title = item_dict.get(\"title\")\n    self.description = item_dict.get(\"description\")\n    self._jobs = []\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem","title":"<code>KTableItem</code>","text":"<p>               Bases: <code>KItem</code></p> <p>Represents a table dataset item in the Koordinates system.</p> <p>Inherits from KItem and provides methods to interact with table datasets, including querying records, exporting data, and retrieving changesets.</p> <p>Attributes:</p> Name Type Description <code>_supports_changesets</code> <code>bool or None</code> <p>Whether the item supports changesets.</p> <code>_services</code> <code>list or None</code> <p>Cached list of services for this item.</p> <code>_kserver</code> <code>KServer</code> <p>The KServer instance this item belongs to.</p> <code>_raw_json</code> <code>dict</code> <p>The raw JSON dictionary representing the item.</p> <code>id</code> <code>str</code> <p>The unique identifier of the item.</p> <code>type</code> <code>str</code> <p>The type of the item (should be 'table').</p> <code>kind</code> <code>str</code> <p>The kind of the item (should be 'table').</p> <code>title</code> <code>str</code> <p>The title of the item.</p> <code>description</code> <code>str</code> <p>The description of the item.</p> <code>_jobs</code> <code>list</code> <p>List of JobResult objects associated with this item.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>class KTableItem(KItem):\n    \"\"\"\n    Represents a table dataset item in the Koordinates system.\n\n    Inherits from KItem and provides methods to interact with table datasets, including\n    querying records, exporting data, and retrieving changesets.\n\n    Attributes:\n        _supports_changesets (bool or None): Whether the item supports changesets.\n        _services (list or None): Cached list of services for this item.\n        _kserver (KServer): The KServer instance this item belongs to.\n        _raw_json (dict): The raw JSON dictionary representing the item.\n        id (str): The unique identifier of the item.\n        type (str): The type of the item (should be 'table').\n        kind (str): The kind of the item (should be 'table').\n        title (str): The title of the item.\n        description (str): The description of the item.\n        _jobs (list): List of JobResult objects associated with this item.\n    \"\"\"\n\n    def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n        \"\"\"\n        Initializes the KTableItem with a dictionary of item details.\n\n        Parameters:\n            kserver (KServer): The KServer instance this item belongs to.\n            item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n        Returns:\n            None\n        \"\"\"\n        super().__init__(kserver, item_dict)\n        self._supports_changesets = None\n        self._services = None\n        logger.debug(f\"Initializing KTableItem with id: {self.id}, title: {self.title}\")\n\n    @property\n    def fields(self) -&gt; list:\n        \"\"\"\n        Returns the fields of the item.\n\n        Returns:\n            list: A list of fields associated with the item.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"fields\", [])\n\n    @property\n    def primary_key_fields(self) -&gt; list:\n        \"\"\"\n        Returns the primary key fields of the item.\n\n        Returns:\n            list: A list of primary key fields associated with the item.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"primary_key_fields\", [])\n\n    @property\n    def feature_count(self) -&gt; int | None:\n        \"\"\"\n        Returns the number of features in the item.\n\n        Returns:\n            int: The number of features associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"feature_count\", None)\n\n    @property\n    def export_formats(self) -&gt; list:\n        \"\"\"\n        Returns the export formats available for the item.\n\n        Returns:\n            list: A list of export formats associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"export_formats\", None)\n\n    @property\n    def supports_changesets(self) -&gt; bool:\n        \"\"\"\n        Returns whether the item supports changes.\n        NB: Not really sure how reliable this is, but seems to be the\n        only way to determine if the item supports changesets.\n\n        Returns:\n            bool: True if the item supports changes, False otherwise.\n        \"\"\"\n        if self._supports_changesets is None:\n            logger.debug(f\"Checking if item with id: {self.id} supports changesets\")\n            self._supports_changesets = any(\n                service.get(\"key\") == \"wfs-changesets\" for service in self.services\n            )\n\n        return self._supports_changesets\n\n    @property\n    def _wfs_url(self) -&gt; str:\n        \"\"\"\n        Returns the WFS URL for the item.\n\n        Returns:\n            str: The WFS URL associated with the item.\n            example: \"https://data.linz.govt.nz/services/wfs/layer-12345\"\n        \"\"\"\n        return f\"{self._kserver._service_url}wfs/\"\n\n    def get_wfs_service(self) -&gt; str:\n        \"\"\"\n        Returns a string that is the URL for the WFS service.\n\n        Returns:\n            str: The URL for the WFS service.\n        \"\"\"\n\n        logger.debug(f\"Creating WFS service for item with id: {self.id}\")\n        wfs_service = self._kserver.wfs.operations\n\n    def query_json(self, cql_filter: str = None, **kwargs: Any) -&gt; dict:\n        \"\"\"\n        Executes a WFS query on the item and returns the result as JSON.\n\n        Parameters:\n            cql_filter (str, optional): The CQL filter to apply to the query.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            dict: The result of the WFS query in JSON format.\n        \"\"\"\n        logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n        result = wfs_features.download_wfs_data(\n            url=self._wfs_url,\n            api_key=self._kserver._api_key,\n            typeNames=f\"{self.type}-{self.id}\",\n            cql_filter=cql_filter,\n            **kwargs,\n        )\n\n        return result\n\n    def query(self, cql_filter: str = None, **kwargs: Any) -&gt; dict:\n        \"\"\"\n        Executes a WFS query on the item and returns the result as a DataFrame.\n\n        Parameters:\n            cql_filter (str, optional): The CQL filter to apply to the query.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            pandas.DataFrame: The result of the WFS query as a DataFrame.\n        \"\"\"\n        logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n        result = self.query_json(cql_filter=cql_filter, **kwargs)\n\n        df = json_to_df(result, fields=self.fields)\n        return df\n\n    def get_changeset_json(\n        self, from_time: str, to_time: str = None, cql_filter: str = None, **kwargs: Any\n    ) -&gt; dict:\n        \"\"\"\n        Retrieves a changeset for the item in JSON format.\n\n        Parameters:\n            from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n            to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n            cql_filter (str, optional): The CQL filter to apply to the changeset query.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            dict: The changeset data in JSON format.\n        \"\"\"\n        if not self.supports_changesets:\n            logger.error(f\"Item with id: {self.id} does not support changesets.\")\n            raise KServerError(\"This item does not support changesets.\")\n\n        if to_time is None:\n            to_time = datetime.now().isoformat()\n        logger.debug(\n            f\"Fetching changeset for item with id: {self.id} from {from_time} to {to_time}\"\n        )\n\n        viewparams = f\"from:{from_time};to:{to_time}\"\n\n        result = wfs_features.download_wfs_data(\n            url=self._wfs_url,\n            api_key=self._kserver._api_key,\n            typeNames=f\"{self.type}-{self.id}-changeset\",\n            viewparams=viewparams,\n            cql_filter=cql_filter,\n            **kwargs,\n        )\n\n        return result\n\n    def get_changeset(\n        self, from_time: str, to_time: str = None, cql_filter: str = None, **kwargs: Any\n    ) -&gt; dict:\n        \"\"\"\n        Retrieves a changeset for the item and returns it as a DataFrame.\n\n        Parameters:\n            from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n            to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n            cql_filter (str, optional): The CQL filter to apply to the changeset query.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            pandas.DataFrame: The changeset data as a DataFrame.\n        \"\"\"\n\n        result = self.get_changeset_json(\n            from_time=from_time, to_time=to_time, cql_filter=cql_filter, **kwargs\n        )\n\n        df = json_to_df(result, fields=self.fields)\n        return df\n\n    @property\n    def services(self) -&gt; list:\n        \"\"\"\n        Returns the services associated with the item.\n\n        Returns:\n            list: A list of services associated with the item.\n        \"\"\"\n\n        if self._services is None:\n            logger.debug(f\"Fetching services for item with id: {self.id}\")\n            url = self._kserver._api_url + f\"tables/{self.id}/services/\"\n            self._services = self._kserver.get(url)\n        logger.debug(\n            f\"Returning {len(self._services)} services for item with id: {self.id}\"\n        )\n        return self._services\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Resets the KTableItem instance, clearing cached properties.\n        This is useful for refreshing the item state.\n        \"\"\"\n        logger.info(f\"Resetting KTableItem with id: {self.id}\")\n        self._supports_changesets = None\n        self._services = None\n        self._raw_json = None\n\n    def _resolve_export_format(self, export_format: str) -&gt; str:\n        \"\"\"\n        Validates if the export format is supported by the item and returns the mimetype.\n\n        Parameters:\n            export_format (str): The format to validate.\n\n        Returns:\n            str: The mimetype of the export format if supported.\n\n        Raises:\n            ValueError: If the export format is not supported by this item.\n        \"\"\"\n        logger.debug(\n            f\"Validating export format: {export_format} for item with id: {self.id}\"\n        )\n        mimetype = None\n\n        # check if the export format is either any of the names or mimetypes in the example_formats\n        export_format = export_format.lower()\n\n        # Handle special cases for export formats geopackage and sqlite as it seems a\n        # strange string argument to expect a user to pass in\n        if export_format in (\"geopackage\", \"sqlite\"):\n            export_format = \"GeoPackage / SQLite\".lower()\n\n        for f in self.export_formats:\n            if export_format in (f[\"name\"].lower(), f[\"mimetype\"].lower()):\n                mimetype = f[\"mimetype\"]\n\n        if mimetype is None:\n            raise ValueError(\n                f\"Export format {export_format} is not supported by this item. Refer supported formats using : itm.export_formats\"\n            )\n\n        logger.debug(f\"Resolved export format: {mimetype} from {export_format}\")\n        return mimetype\n\n    def validate_export_request(\n        self,\n        export_format: str,\n        **kwargs: Any,\n    ) -&gt; bool:\n        \"\"\"\n        Validates the export request parameters for the item.\n\n        Parameters:\n            export_format (str): The format to export the item in.\n            **kwargs: Additional parameters for the export request.\n\n        Returns:\n            bool: True if the export request is valid, False otherwise.\n        \"\"\"\n\n        export_format = self._resolve_export_format(export_format)\n\n        # log out all the input parameters including kwargs\n        logger.info(\n            f\"Validating export request for item with id: {self.id}, {export_format=}, {kwargs=}\"\n        )\n\n        return export_features.validate_export_params(\n            self._kserver._api_url,\n            self._kserver._api_key,\n            self.id,\n            self.type,\n            self.kind,\n            export_format,\n            **kwargs,\n        )\n\n    def export(\n        self,\n        export_format: str,\n        poll_interval: int = 10,\n        timeout: int = 600,\n        **kwargs: Any,\n    ) -&gt; JobResult:\n        \"\"\"\n        Exports the item in the specified format.\n\n        Parameters:\n            export_format (str): The format to export the item in.\n            poll_interval (int, optional): The interval in seconds to poll the export job status. Default is 10 seconds.\n            timeout (int, optional): The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).\n            **kwargs: Additional parameters for the export request.\n\n        Returns:\n            JobResult: A JobResult instance containing the export job details.\n        \"\"\"\n\n        logger.debug(f\"Exporting item with id: {self.id} in format: {export_format}\")\n\n        export_format = self._resolve_export_format(export_format)\n\n        validate_export_request = self.validate_export_request(\n            export_format,\n            **kwargs,\n        )\n\n        if not validate_export_request:\n            logger.error(\n                f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n            )\n            raise ValueError(\n                f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n            )\n\n        export_request = export_features.request_export(\n            self._kserver._api_url,\n            self._kserver._api_key,\n            self.id,\n            self.type,\n            self.kind,\n            export_format,\n            **kwargs,\n        )\n\n        job_result = JobResult(\n            export_request, self._kserver, poll_interval=poll_interval, timeout=timeout\n        )\n        self._jobs.append(job_result)\n        logger.info(\n            f\"Export job created for item with id: {self.id}, job id: {job_result.id}\"\n        )\n        return job_result\n\n    def __repr__(self) -&gt; str:\n        return f\"KTableItem(id={self.id}, title={self.title}, type={self.type}, kind={self.kind})\"\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.export_formats","title":"<code>export_formats</code>  <code>property</code>","text":"<p>Returns the export formats available for the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of export formats associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.feature_count","title":"<code>feature_count</code>  <code>property</code>","text":"<p>Returns the number of features in the item.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int | None</code> <p>The number of features associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.fields","title":"<code>fields</code>  <code>property</code>","text":"<p>Returns the fields of the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of fields associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.primary_key_fields","title":"<code>primary_key_fields</code>  <code>property</code>","text":"<p>Returns the primary key fields of the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of primary key fields associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.services","title":"<code>services</code>  <code>property</code>","text":"<p>Returns the services associated with the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of services associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.supports_changesets","title":"<code>supports_changesets</code>  <code>property</code>","text":"<p>Returns whether the item supports changes. NB: Not really sure how reliable this is, but seems to be the only way to determine if the item supports changesets.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the item supports changes, False otherwise.</p>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.__init__","title":"<code>__init__(kserver, item_dict)</code>","text":"<p>Initializes the KTableItem with a dictionary of item details.</p> <p>Parameters:</p> Name Type Description Default <code>kserver</code> <code>KServer</code> <p>The KServer instance this item belongs to.</p> required <code>item_dict</code> <code>dict</code> <p>A dictionary containing the item's details, typically from an API response.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n    \"\"\"\n    Initializes the KTableItem with a dictionary of item details.\n\n    Parameters:\n        kserver (KServer): The KServer instance this item belongs to.\n        item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n    Returns:\n        None\n    \"\"\"\n    super().__init__(kserver, item_dict)\n    self._supports_changesets = None\n    self._services = None\n    logger.debug(f\"Initializing KTableItem with id: {self.id}, title: {self.title}\")\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.export","title":"<code>export(export_format, poll_interval=10, timeout=600, **kwargs)</code>","text":"<p>Exports the item in the specified format.</p> <p>Parameters:</p> Name Type Description Default <code>export_format</code> <code>str</code> <p>The format to export the item in.</p> required <code>poll_interval</code> <code>int</code> <p>The interval in seconds to poll the export job status. Default is 10 seconds.</p> <code>10</code> <code>timeout</code> <code>int</code> <p>The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).</p> <code>600</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export request.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>JobResult</code> <code>JobResult</code> <p>A JobResult instance containing the export job details.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def export(\n    self,\n    export_format: str,\n    poll_interval: int = 10,\n    timeout: int = 600,\n    **kwargs: Any,\n) -&gt; JobResult:\n    \"\"\"\n    Exports the item in the specified format.\n\n    Parameters:\n        export_format (str): The format to export the item in.\n        poll_interval (int, optional): The interval in seconds to poll the export job status. Default is 10 seconds.\n        timeout (int, optional): The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).\n        **kwargs: Additional parameters for the export request.\n\n    Returns:\n        JobResult: A JobResult instance containing the export job details.\n    \"\"\"\n\n    logger.debug(f\"Exporting item with id: {self.id} in format: {export_format}\")\n\n    export_format = self._resolve_export_format(export_format)\n\n    validate_export_request = self.validate_export_request(\n        export_format,\n        **kwargs,\n    )\n\n    if not validate_export_request:\n        logger.error(\n            f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n        )\n        raise ValueError(\n            f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n        )\n\n    export_request = export_features.request_export(\n        self._kserver._api_url,\n        self._kserver._api_key,\n        self.id,\n        self.type,\n        self.kind,\n        export_format,\n        **kwargs,\n    )\n\n    job_result = JobResult(\n        export_request, self._kserver, poll_interval=poll_interval, timeout=timeout\n    )\n    self._jobs.append(job_result)\n    logger.info(\n        f\"Export job created for item with id: {self.id}, job id: {job_result.id}\"\n    )\n    return job_result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.get_changeset","title":"<code>get_changeset(from_time, to_time=None, cql_filter=None, **kwargs)</code>","text":"<p>Retrieves a changeset for the item and returns it as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>from_time</code> <code>str</code> <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p> required <code>to_time</code> <code>str</code> <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p> <code>None</code> <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the changeset query.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>pandas.DataFrame: The changeset data as a DataFrame.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def get_changeset(\n    self, from_time: str, to_time: str = None, cql_filter: str = None, **kwargs: Any\n) -&gt; dict:\n    \"\"\"\n    Retrieves a changeset for the item and returns it as a DataFrame.\n\n    Parameters:\n        from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n        to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n        cql_filter (str, optional): The CQL filter to apply to the changeset query.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        pandas.DataFrame: The changeset data as a DataFrame.\n    \"\"\"\n\n    result = self.get_changeset_json(\n        from_time=from_time, to_time=to_time, cql_filter=cql_filter, **kwargs\n    )\n\n    df = json_to_df(result, fields=self.fields)\n    return df\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.get_changeset_json","title":"<code>get_changeset_json(from_time, to_time=None, cql_filter=None, **kwargs)</code>","text":"<p>Retrieves a changeset for the item in JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>from_time</code> <code>str</code> <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p> required <code>to_time</code> <code>str</code> <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p> <code>None</code> <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the changeset query.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The changeset data in JSON format.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def get_changeset_json(\n    self, from_time: str, to_time: str = None, cql_filter: str = None, **kwargs: Any\n) -&gt; dict:\n    \"\"\"\n    Retrieves a changeset for the item in JSON format.\n\n    Parameters:\n        from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n        to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n        cql_filter (str, optional): The CQL filter to apply to the changeset query.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        dict: The changeset data in JSON format.\n    \"\"\"\n    if not self.supports_changesets:\n        logger.error(f\"Item with id: {self.id} does not support changesets.\")\n        raise KServerError(\"This item does not support changesets.\")\n\n    if to_time is None:\n        to_time = datetime.now().isoformat()\n    logger.debug(\n        f\"Fetching changeset for item with id: {self.id} from {from_time} to {to_time}\"\n    )\n\n    viewparams = f\"from:{from_time};to:{to_time}\"\n\n    result = wfs_features.download_wfs_data(\n        url=self._wfs_url,\n        api_key=self._kserver._api_key,\n        typeNames=f\"{self.type}-{self.id}-changeset\",\n        viewparams=viewparams,\n        cql_filter=cql_filter,\n        **kwargs,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.get_wfs_service","title":"<code>get_wfs_service()</code>","text":"<p>Returns a string that is the URL for the WFS service.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The URL for the WFS service.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def get_wfs_service(self) -&gt; str:\n    \"\"\"\n    Returns a string that is the URL for the WFS service.\n\n    Returns:\n        str: The URL for the WFS service.\n    \"\"\"\n\n    logger.debug(f\"Creating WFS service for item with id: {self.id}\")\n    wfs_service = self._kserver.wfs.operations\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.query","title":"<code>query(cql_filter=None, **kwargs)</code>","text":"<p>Executes a WFS query on the item and returns the result as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the query.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>pandas.DataFrame: The result of the WFS query as a DataFrame.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def query(self, cql_filter: str = None, **kwargs: Any) -&gt; dict:\n    \"\"\"\n    Executes a WFS query on the item and returns the result as a DataFrame.\n\n    Parameters:\n        cql_filter (str, optional): The CQL filter to apply to the query.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        pandas.DataFrame: The result of the WFS query as a DataFrame.\n    \"\"\"\n    logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n    result = self.query_json(cql_filter=cql_filter, **kwargs)\n\n    df = json_to_df(result, fields=self.fields)\n    return df\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.query_json","title":"<code>query_json(cql_filter=None, **kwargs)</code>","text":"<p>Executes a WFS query on the item and returns the result as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the query.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The result of the WFS query in JSON format.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def query_json(self, cql_filter: str = None, **kwargs: Any) -&gt; dict:\n    \"\"\"\n    Executes a WFS query on the item and returns the result as JSON.\n\n    Parameters:\n        cql_filter (str, optional): The CQL filter to apply to the query.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        dict: The result of the WFS query in JSON format.\n    \"\"\"\n    logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n    result = wfs_features.download_wfs_data(\n        url=self._wfs_url,\n        api_key=self._kserver._api_key,\n        typeNames=f\"{self.type}-{self.id}\",\n        cql_filter=cql_filter,\n        **kwargs,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.reset","title":"<code>reset()</code>","text":"<p>Resets the KTableItem instance, clearing cached properties. This is useful for refreshing the item state.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Resets the KTableItem instance, clearing cached properties.\n    This is useful for refreshing the item state.\n    \"\"\"\n    logger.info(f\"Resetting KTableItem with id: {self.id}\")\n    self._supports_changesets = None\n    self._services = None\n    self._raw_json = None\n</code></pre>"},{"location":"reference/#pykaahma_linz.KTableItem.KTableItem.validate_export_request","title":"<code>validate_export_request(export_format, **kwargs)</code>","text":"<p>Validates the export request parameters for the item.</p> <p>Parameters:</p> Name Type Description Default <code>export_format</code> <code>str</code> <p>The format to export the item in.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export request.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the export request is valid, False otherwise.</p> Source code in <code>src\\pykaahma_linz\\KTableItem.py</code> <pre><code>def validate_export_request(\n    self,\n    export_format: str,\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"\n    Validates the export request parameters for the item.\n\n    Parameters:\n        export_format (str): The format to export the item in.\n        **kwargs: Additional parameters for the export request.\n\n    Returns:\n        bool: True if the export request is valid, False otherwise.\n    \"\"\"\n\n    export_format = self._resolve_export_format(export_format)\n\n    # log out all the input parameters including kwargs\n    logger.info(\n        f\"Validating export request for item with id: {self.id}, {export_format=}, {kwargs=}\"\n    )\n\n    return export_features.validate_export_params(\n        self._kserver._api_url,\n        self._kserver._api_key,\n        self.id,\n        self.type,\n        self.kind,\n        export_format,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem","title":"<code>KVectorItem</code>","text":"<p>               Bases: <code>KItem</code></p> <p>Represents a vector dataset item in the Koordinates system.</p> <p>Inherits from KItem and provides methods to interact with vector datasets, including querying features, exporting data, and retrieving changesets.</p> <p>Attributes:</p> Name Type Description <code>_supports_changesets</code> <code>bool or None</code> <p>Whether the item supports changesets.</p> <code>_services</code> <code>list or None</code> <p>Cached list of services for this item.</p> <code>_kserver</code> <code>KServer</code> <p>The KServer instance this item belongs to.</p> <code>_raw_json</code> <code>dict</code> <p>The raw JSON dictionary representing the item.</p> <code>id</code> <code>str</code> <p>The unique identifier of the item.</p> <code>type</code> <code>str</code> <p>The type of the item (should be 'layer').</p> <code>kind</code> <code>str</code> <p>The kind of the item (should be 'vector').</p> <code>title</code> <code>str</code> <p>The title of the item.</p> <code>description</code> <code>str</code> <p>The description of the item.</p> <code>_jobs</code> <code>list</code> <p>List of JobResult objects associated with this item.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>class KVectorItem(KItem):\n    \"\"\"\n    Represents a vector dataset item in the Koordinates system.\n\n    Inherits from KItem and provides methods to interact with vector datasets, including\n    querying features, exporting data, and retrieving changesets.\n\n    Attributes:\n        _supports_changesets (bool or None): Whether the item supports changesets.\n        _services (list or None): Cached list of services for this item.\n        _kserver (KServer): The KServer instance this item belongs to.\n        _raw_json (dict): The raw JSON dictionary representing the item.\n        id (str): The unique identifier of the item.\n        type (str): The type of the item (should be 'layer').\n        kind (str): The kind of the item (should be 'vector').\n        title (str): The title of the item.\n        description (str): The description of the item.\n        _jobs (list): List of JobResult objects associated with this item.\n    \"\"\"\n\n    def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n        \"\"\"\n        Initializes the KVectorItem with a dictionary of item details.\n\n        Parameters:\n            kserver (KServer): The KServer instance this item belongs to.\n            item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n        Returns:\n            None\n        \"\"\"\n        super().__init__(kserver, item_dict)\n        self._supports_changesets = None\n        self._services = None\n        logger.debug(\n            f\"Initializing KVectorItem with id: {self.id}, title: {self.title}\"\n        )\n\n    @property\n    def fields(self) -&gt; list:\n        \"\"\"\n        Returns the fields of the item.\n\n        Returns:\n            list: A list of fields associated with the item.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"fields\", [])\n\n    @property\n    def epsg(self) -&gt; int | None:\n        \"\"\"\n        Returns the EPSG code of the item.\n\n        Returns:\n            int: The EPSG code associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"crs\", {}).get(\"srid\", None)\n\n    @property\n    def primary_key_fields(self) -&gt; list:\n        \"\"\"\n        Returns the primary key fields of the item.\n\n        Returns:\n            list: A list of primary key fields associated with the item.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"primary_key_fields\", [])\n\n    @property\n    def geometry_type(self) -&gt; str | None:\n        \"\"\"\n        Returns the geometry type of the item.\n\n        Returns:\n            str: The geometry type associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"geometry_type\", None)\n\n    @property\n    def feature_count(self) -&gt; int | None:\n        \"\"\"\n        Returns the number of features in the item.\n\n        Returns:\n            int: The number of features associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"feature_count\", None)\n\n    @property\n    def extent(self) -&gt; dict | None:\n        \"\"\"\n        Returns the extent of the item.\n\n        Returns:\n            dict: A dictionary containing the extent of the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"extent\", None)\n\n    @property\n    def export_formats(self) -&gt; list | None:\n        \"\"\"\n        Returns the export formats available for the item.\n\n        Returns:\n            list: A list of export formats associated with the item, or None if not available.\n        \"\"\"\n        return self._raw_json.get(\"data\", {}).get(\"export_formats\", None)\n\n    @property\n    def supports_changesets(self) -&gt; bool:\n        \"\"\"\n        Returns whether the item supports changes.\n        NB: Not really sure how reliable this is, but seems to be the\n        only way to determine if the item supports changesets.\n\n        Returns:\n            bool: True if the item supports changes, False otherwise.\n        \"\"\"\n        if self._supports_changesets is None:\n            logger.debug(f\"Checking if item with id: {self.id} supports changesets\")\n            self._supports_changesets = any(\n                service.get(\"key\") == \"wfs-changesets\" for service in self.services\n            )\n\n        return self._supports_changesets\n\n    @property\n    def _wfs_url(self) -&gt; str:\n        \"\"\"\n        Returns the WFS URL for the item.\n\n        Returns:\n            str: The WFS URL associated with the item.\n            example: \"https://data.linz.govt.nz/services/wfs/layer-12345\"\n        \"\"\"\n        return f\"{self._kserver._service_url}wfs/\"\n\n    def get_wfs_service(self) -&gt; str:\n        \"\"\"\n        Returns the item's WFS service URL.\n\n        Returns:\n            str: The WFS service URL.\n        \"\"\"\n\n        logger.debug(f\"Creating WFS service for item with id: {self.id}\")\n        wfs_service = self._kserver.wfs.operations\n\n    def query_json(\n        self,\n        cql_filter: str = None,\n        srsName: str = None,\n        bbox: str | gpd.GeoDataFrame = None,\n        **kwargs: Any,\n    ) -&gt; dict:\n        \"\"\"\n        Executes a WFS query on the item and returns the result as JSON.\n\n        Parameters:\n            cql_filter (str, optional): The CQL filter to apply to the query.\n            srsName (str, optional): The spatial reference system name to use for the query.\n            bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the query.\n                If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            dict: The result of the WFS query in JSON format.\n        \"\"\"\n        logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n        if isinstance(bbox, gpd.GeoDataFrame):\n            logger.debug(\n                f\"Converting bbox GeoDataFrame to GeoJSON for item with id: {self.id}\"\n            )\n            bbox = gdf_to_bbox(bbox)\n\n        result = wfs_features.download_wfs_data(\n            url=self._wfs_url,\n            api_key=self._kserver._api_key,\n            typeNames=f\"{self.type}-{self.id}\",\n            cql_filter=cql_filter,\n            srsName=srsName or f\"EPSG:{self.epsg}\" if self.epsg else None,\n            bbox=bbox,\n            **kwargs,\n        )\n\n        return result\n\n    def query(\n        self,\n        cql_filter: str = None,\n        srsName: str = None,\n        bbox: str | gpd.GeoDataFrame = None,\n        **kwargs: Any,\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"\n        Executes a WFS query on the item.\n\n        Args:\n            cql_filter (str): The WFS query to execute.\n\n        Returns:\n            dict: The result of the WFS query.\n        \"\"\"\n        logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n        result = self.query_json(\n            cql_filter=cql_filter,\n            srsName=srsName or f\"EPSG:{self.epsg}\" if self.epsg else None,\n            bbox=bbox,\n            **kwargs,\n        )\n\n        gdf = geojson_to_gdf(result, epsg=self.epsg, fields=self.fields)\n        return gdf\n\n    def get_changeset_json(\n        self,\n        from_time: str,\n        to_time: str = None,\n        cql_filter: str = None,\n        bbox: str | gpd.GeoDataFrame = None,\n        **kwargs: Any,\n    ) -&gt; dict:\n        \"\"\"\n        Retrieves a changeset for the item in JSON format.\n\n        Parameters:\n            from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n            to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n            cql_filter (str, optional): The CQL filter to apply to the changeset query.\n            bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the changeset query.\n                If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            dict: The changeset data in JSON format.\n        \"\"\"\n\n        if not self.supports_changesets:\n            logger.error(f\"Item with id: {self.id} does not support changesets.\")\n            raise KServerError(\"This item does not support changesets.\")\n\n        if to_time is None:\n            to_time = datetime.now().isoformat()\n        logger.debug(\n            f\"Fetching changeset for item with id: {self.id} from {from_time} to {to_time}\"\n        )\n\n        viewparams = f\"from:{from_time};to:{to_time}\"\n\n        if isinstance(bbox, gpd.GeoDataFrame):\n            logger.debug(\n                f\"Converting bbox GeoDataFrame to GeoJSON for item with id: {self.id}\"\n            )\n            bbox = gdf_to_bbox(bbox)\n\n        result = wfs_features.download_wfs_data(\n            url=self._wfs_url,\n            api_key=self._kserver._api_key,\n            typeNames=f\"layer-{self.id}-changeset\",\n            viewparams=viewparams,\n            cql_filter=cql_filter,\n            srsName=f\"EPSG:{self.epsg}\" if self.epsg else None,\n            bbox=bbox,\n            **kwargs,\n        )\n        return result\n\n    def get_changeset(\n        self,\n        from_time: str,\n        to_time: str = None,\n        cql_filter: str = None,\n        bbox: str | gpd.GeoDataFrame = None,\n        **kwargs: Any,\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"\n        Retrieves a changeset for the item and returns it as a GeoDataFrame.\n\n        Parameters:\n            from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n            to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n            cql_filter (str, optional): The CQL filter to apply to the changeset query.\n            bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the changeset query.\n                If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n            **kwargs: Additional parameters for the WFS query.\n\n        Returns:\n            gpd.GeoDataFrame: The changeset data as a GeoDataFrame.\n        \"\"\"\n\n        result = self.get_changeset_json(\n            from_time=from_time,\n            to_time=to_time,\n            cql_filter=cql_filter,\n            bbox=bbox,\n            **kwargs,\n        )\n\n        gdf = geojson_to_gdf(result, epsg=self.epsg, fields=self.fields)\n        return gdf\n\n    @property\n    def services(self) -&gt; list:\n        \"\"\"\n        Returns the services associated with the item.\n\n        Returns:\n            list: A list of services associated with the item.\n        \"\"\"\n\n        if self._services is None:\n            logger.debug(f\"Fetching services for item with id: {self.id}\")\n            url = self._kserver._api_url + f\"layers/{self.id}/services/\"\n            self._services = self._kserver.get(url)\n        logger.debug(\n            f\"Returning {len(self._services)} services for item with id: {self.id}\"\n        )\n        return self._services\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Resets the KVectorItem instance, clearing cached properties.\n        This is useful for refreshing the item state.\n        \"\"\"\n        logger.info(f\"Resetting KVectorItem with id: {self.id}\")\n        self._supports_changesets = None\n        self._services = None\n        self._raw_json = None\n\n    def _resolve_export_format(self, export_format: str) -&gt; str:\n        \"\"\"\n        Validates if the export format is supported by the item and returns the mimetype.\n\n        Parameters:\n            export_format (str): The format to validate.\n\n        Returns:\n            str: The mimetype of the export format if supported.\n\n        Raises:\n            ValueError: If the export format is not supported by this item.\n        \"\"\"\n        logger.debug(\n            f\"Validating export format: {export_format} for item with id: {self.id}\"\n        )\n        mimetype = None\n\n        # check if the export format is either any of the names or mimetypes in the example_formats\n        export_format = export_format.lower()\n\n        # Handle special cases for export formats geopackage and sqlite as it seems a\n        # strange string argument to expect a user to pass in\n        if export_format in (\"geopackage\", \"sqlite\"):\n            export_format = \"GeoPackage / SQLite\".lower()\n\n        for f in self.export_formats:\n            if export_format in (f[\"name\"].lower(), f[\"mimetype\"].lower()):\n                mimetype = f[\"mimetype\"]\n\n        if mimetype is None:\n            raise ValueError(\n                f\"Export format {export_format} is not supported by this item. Refer supported formats using : itm.export_formats\"\n            )\n\n        logger.debug(f\"Resolved export format: {mimetype} from {export_format}\")\n        return mimetype\n\n    def validate_export_request(\n        self,\n        export_format: str,\n        crs: str = None,\n        extent: dict = None,\n        **kwargs: Any,\n    ) -&gt; bool:\n        \"\"\"\n        Validates the export request parameters for the item.\n\n        Parameters:\n            export_format (str): The format to export the item in.\n            crs (str, optional): The coordinate reference system to use for the export.\n            extent (dict, optional): The extent to use for the export. Should be a GeoJSON dictionary.\n            **kwargs: Additional parameters for the export request.\n\n        Returns:\n            bool: True if the export request is valid, False otherwise.\n        \"\"\"\n\n        export_format = self._resolve_export_format(export_format)\n\n        # log out all the input parameters including kwargs\n        logger.info(\n            f\"Validating export request for item with id: {self.id}, {export_format=}, {crs=}, {extent=},  {kwargs=}\"\n        )\n\n        return export_features.validate_export_params(\n            self._kserver._api_url,\n            self._kserver._api_key,\n            self.id,\n            self.type,\n            self.kind,\n            export_format,\n            crs,\n            extent,\n            **kwargs,\n        )\n\n    def export(\n        self,\n        export_format: str,\n        crs: str = None,\n        extent: dict | gpd.GeoDataFrame = None,\n        poll_interval: int = 10,\n        timeout: int = 600,\n        **kwargs: Any,\n    ) -&gt; JobResult:\n        \"\"\"\n        Exports the item in the specified format.\n\n        Parameters:\n            export_format (str): The format to export the item in.\n            crs (str, optional): The coordinate reference system to use for the export.\n            extent (dict or gpd.GeoDataFrame, optional): The extent to use for the export. Should be a GeoJSON dictionary or a GeoDataFrame.\n            poll_interval (int, optional): The interval in seconds to poll the export job status. Default is 10 seconds.\n            timeout (int, optional): The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).\n            **kwargs: Additional parameters for the export request.\n\n        Returns:\n            JobResult: A JobResult instance containing the export job details.\n        \"\"\"\n        logger.debug(f\"Exporting item with id: {self.id} in format: {export_format}\")\n\n        if isinstance(extent, gpd.GeoDataFrame):\n            logger.debug(\n                f\"Converting extent GeoDataFrame to GeoJSON for item with id: {self.id}\"\n            )\n            extent = gdf_to_single_polygon_geojson(extent)\n\n        export_format = self._resolve_export_format(export_format)\n\n        validate_export_request = self.validate_export_request(\n            export_format,\n            crs=crs,\n            extent=extent,\n            **kwargs,\n        )\n\n        if not validate_export_request:\n            logger.error(\n                f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n            )\n            raise ValueError(\n                f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n            )\n\n        export_request = export_features.request_export(\n            self._kserver._api_url,\n            self._kserver._api_key,\n            self.id,\n            self.type,\n            self.kind,\n            export_format,\n            crs=crs,\n            extent=extent,\n            **kwargs,\n        )\n\n        job_result = JobResult(\n            export_request, self._kserver, poll_interval=poll_interval, timeout=timeout\n        )\n        self._jobs.append(job_result)\n        logger.info(\n            f\"Export job created for item with id: {self.id}, job id: {job_result.id}\"\n        )\n        return job_result\n\n    def __repr__(self) -&gt; str:\n        return f\"KVectorItem(id={self.id}, title={self.title}, type={self.type}, kind={self.kind})\"\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.epsg","title":"<code>epsg</code>  <code>property</code>","text":"<p>Returns the EPSG code of the item.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int | None</code> <p>The EPSG code associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.export_formats","title":"<code>export_formats</code>  <code>property</code>","text":"<p>Returns the export formats available for the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list | None</code> <p>A list of export formats associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.extent","title":"<code>extent</code>  <code>property</code>","text":"<p>Returns the extent of the item.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict | None</code> <p>A dictionary containing the extent of the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.feature_count","title":"<code>feature_count</code>  <code>property</code>","text":"<p>Returns the number of features in the item.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int | None</code> <p>The number of features associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.fields","title":"<code>fields</code>  <code>property</code>","text":"<p>Returns the fields of the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of fields associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.geometry_type","title":"<code>geometry_type</code>  <code>property</code>","text":"<p>Returns the geometry type of the item.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str | None</code> <p>The geometry type associated with the item, or None if not available.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.primary_key_fields","title":"<code>primary_key_fields</code>  <code>property</code>","text":"<p>Returns the primary key fields of the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of primary key fields associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.services","title":"<code>services</code>  <code>property</code>","text":"<p>Returns the services associated with the item.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of services associated with the item.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.supports_changesets","title":"<code>supports_changesets</code>  <code>property</code>","text":"<p>Returns whether the item supports changes. NB: Not really sure how reliable this is, but seems to be the only way to determine if the item supports changesets.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the item supports changes, False otherwise.</p>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.__init__","title":"<code>__init__(kserver, item_dict)</code>","text":"<p>Initializes the KVectorItem with a dictionary of item details.</p> <p>Parameters:</p> Name Type Description Default <code>kserver</code> <code>KServer</code> <p>The KServer instance this item belongs to.</p> required <code>item_dict</code> <code>dict</code> <p>A dictionary containing the item's details, typically from an API response.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def __init__(self, kserver: \"KServer\", item_dict: dict) -&gt; None:\n    \"\"\"\n    Initializes the KVectorItem with a dictionary of item details.\n\n    Parameters:\n        kserver (KServer): The KServer instance this item belongs to.\n        item_dict (dict): A dictionary containing the item's details, typically from an API response.\n\n    Returns:\n        None\n    \"\"\"\n    super().__init__(kserver, item_dict)\n    self._supports_changesets = None\n    self._services = None\n    logger.debug(\n        f\"Initializing KVectorItem with id: {self.id}, title: {self.title}\"\n    )\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.export","title":"<code>export(export_format, crs=None, extent=None, poll_interval=10, timeout=600, **kwargs)</code>","text":"<p>Exports the item in the specified format.</p> <p>Parameters:</p> Name Type Description Default <code>export_format</code> <code>str</code> <p>The format to export the item in.</p> required <code>crs</code> <code>str</code> <p>The coordinate reference system to use for the export.</p> <code>None</code> <code>extent</code> <code>dict or GeoDataFrame</code> <p>The extent to use for the export. Should be a GeoJSON dictionary or a GeoDataFrame.</p> <code>None</code> <code>poll_interval</code> <code>int</code> <p>The interval in seconds to poll the export job status. Default is 10 seconds.</p> <code>10</code> <code>timeout</code> <code>int</code> <p>The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).</p> <code>600</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export request.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>JobResult</code> <code>JobResult</code> <p>A JobResult instance containing the export job details.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def export(\n    self,\n    export_format: str,\n    crs: str = None,\n    extent: dict | gpd.GeoDataFrame = None,\n    poll_interval: int = 10,\n    timeout: int = 600,\n    **kwargs: Any,\n) -&gt; JobResult:\n    \"\"\"\n    Exports the item in the specified format.\n\n    Parameters:\n        export_format (str): The format to export the item in.\n        crs (str, optional): The coordinate reference system to use for the export.\n        extent (dict or gpd.GeoDataFrame, optional): The extent to use for the export. Should be a GeoJSON dictionary or a GeoDataFrame.\n        poll_interval (int, optional): The interval in seconds to poll the export job status. Default is 10 seconds.\n        timeout (int, optional): The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).\n        **kwargs: Additional parameters for the export request.\n\n    Returns:\n        JobResult: A JobResult instance containing the export job details.\n    \"\"\"\n    logger.debug(f\"Exporting item with id: {self.id} in format: {export_format}\")\n\n    if isinstance(extent, gpd.GeoDataFrame):\n        logger.debug(\n            f\"Converting extent GeoDataFrame to GeoJSON for item with id: {self.id}\"\n        )\n        extent = gdf_to_single_polygon_geojson(extent)\n\n    export_format = self._resolve_export_format(export_format)\n\n    validate_export_request = self.validate_export_request(\n        export_format,\n        crs=crs,\n        extent=extent,\n        **kwargs,\n    )\n\n    if not validate_export_request:\n        logger.error(\n            f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n        )\n        raise ValueError(\n            f\"Export validation failed for item with id: {self.id} in format: {export_format}\"\n        )\n\n    export_request = export_features.request_export(\n        self._kserver._api_url,\n        self._kserver._api_key,\n        self.id,\n        self.type,\n        self.kind,\n        export_format,\n        crs=crs,\n        extent=extent,\n        **kwargs,\n    )\n\n    job_result = JobResult(\n        export_request, self._kserver, poll_interval=poll_interval, timeout=timeout\n    )\n    self._jobs.append(job_result)\n    logger.info(\n        f\"Export job created for item with id: {self.id}, job id: {job_result.id}\"\n    )\n    return job_result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.get_changeset","title":"<code>get_changeset(from_time, to_time=None, cql_filter=None, bbox=None, **kwargs)</code>","text":"<p>Retrieves a changeset for the item and returns it as a GeoDataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>from_time</code> <code>str</code> <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p> required <code>to_time</code> <code>str</code> <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p> <code>None</code> <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the changeset query.</p> <code>None</code> <code>bbox</code> <code>str or GeoDataFrame</code> <p>The bounding box to apply to the changeset query. If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The changeset data as a GeoDataFrame.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def get_changeset(\n    self,\n    from_time: str,\n    to_time: str = None,\n    cql_filter: str = None,\n    bbox: str | gpd.GeoDataFrame = None,\n    **kwargs: Any,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Retrieves a changeset for the item and returns it as a GeoDataFrame.\n\n    Parameters:\n        from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n        to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n        cql_filter (str, optional): The CQL filter to apply to the changeset query.\n        bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the changeset query.\n            If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        gpd.GeoDataFrame: The changeset data as a GeoDataFrame.\n    \"\"\"\n\n    result = self.get_changeset_json(\n        from_time=from_time,\n        to_time=to_time,\n        cql_filter=cql_filter,\n        bbox=bbox,\n        **kwargs,\n    )\n\n    gdf = geojson_to_gdf(result, epsg=self.epsg, fields=self.fields)\n    return gdf\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.get_changeset_json","title":"<code>get_changeset_json(from_time, to_time=None, cql_filter=None, bbox=None, **kwargs)</code>","text":"<p>Retrieves a changeset for the item in JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>from_time</code> <code>str</code> <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p> required <code>to_time</code> <code>str</code> <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p> <code>None</code> <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the changeset query.</p> <code>None</code> <code>bbox</code> <code>str or GeoDataFrame</code> <p>The bounding box to apply to the changeset query. If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The changeset data in JSON format.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def get_changeset_json(\n    self,\n    from_time: str,\n    to_time: str = None,\n    cql_filter: str = None,\n    bbox: str | gpd.GeoDataFrame = None,\n    **kwargs: Any,\n) -&gt; dict:\n    \"\"\"\n    Retrieves a changeset for the item in JSON format.\n\n    Parameters:\n        from_time (str): The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").\n        to_time (str, optional): The end time for the changeset query, ISO format. If not provided, the current time is used.\n        cql_filter (str, optional): The CQL filter to apply to the changeset query.\n        bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the changeset query.\n            If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        dict: The changeset data in JSON format.\n    \"\"\"\n\n    if not self.supports_changesets:\n        logger.error(f\"Item with id: {self.id} does not support changesets.\")\n        raise KServerError(\"This item does not support changesets.\")\n\n    if to_time is None:\n        to_time = datetime.now().isoformat()\n    logger.debug(\n        f\"Fetching changeset for item with id: {self.id} from {from_time} to {to_time}\"\n    )\n\n    viewparams = f\"from:{from_time};to:{to_time}\"\n\n    if isinstance(bbox, gpd.GeoDataFrame):\n        logger.debug(\n            f\"Converting bbox GeoDataFrame to GeoJSON for item with id: {self.id}\"\n        )\n        bbox = gdf_to_bbox(bbox)\n\n    result = wfs_features.download_wfs_data(\n        url=self._wfs_url,\n        api_key=self._kserver._api_key,\n        typeNames=f\"layer-{self.id}-changeset\",\n        viewparams=viewparams,\n        cql_filter=cql_filter,\n        srsName=f\"EPSG:{self.epsg}\" if self.epsg else None,\n        bbox=bbox,\n        **kwargs,\n    )\n    return result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.get_wfs_service","title":"<code>get_wfs_service()</code>","text":"<p>Returns the item's WFS service URL.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The WFS service URL.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def get_wfs_service(self) -&gt; str:\n    \"\"\"\n    Returns the item's WFS service URL.\n\n    Returns:\n        str: The WFS service URL.\n    \"\"\"\n\n    logger.debug(f\"Creating WFS service for item with id: {self.id}\")\n    wfs_service = self._kserver.wfs.operations\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.query","title":"<code>query(cql_filter=None, srsName=None, bbox=None, **kwargs)</code>","text":"<p>Executes a WFS query on the item.</p> <p>Parameters:</p> Name Type Description Default <code>cql_filter</code> <code>str</code> <p>The WFS query to execute.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>GeoDataFrame</code> <p>The result of the WFS query.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def query(\n    self,\n    cql_filter: str = None,\n    srsName: str = None,\n    bbox: str | gpd.GeoDataFrame = None,\n    **kwargs: Any,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Executes a WFS query on the item.\n\n    Args:\n        cql_filter (str): The WFS query to execute.\n\n    Returns:\n        dict: The result of the WFS query.\n    \"\"\"\n    logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n    result = self.query_json(\n        cql_filter=cql_filter,\n        srsName=srsName or f\"EPSG:{self.epsg}\" if self.epsg else None,\n        bbox=bbox,\n        **kwargs,\n    )\n\n    gdf = geojson_to_gdf(result, epsg=self.epsg, fields=self.fields)\n    return gdf\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.query_json","title":"<code>query_json(cql_filter=None, srsName=None, bbox=None, **kwargs)</code>","text":"<p>Executes a WFS query on the item and returns the result as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>cql_filter</code> <code>str</code> <p>The CQL filter to apply to the query.</p> <code>None</code> <code>srsName</code> <code>str</code> <p>The spatial reference system name to use for the query.</p> <code>None</code> <code>bbox</code> <code>str or GeoDataFrame</code> <p>The bounding box to apply to the query. If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the WFS query.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The result of the WFS query in JSON format.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def query_json(\n    self,\n    cql_filter: str = None,\n    srsName: str = None,\n    bbox: str | gpd.GeoDataFrame = None,\n    **kwargs: Any,\n) -&gt; dict:\n    \"\"\"\n    Executes a WFS query on the item and returns the result as JSON.\n\n    Parameters:\n        cql_filter (str, optional): The CQL filter to apply to the query.\n        srsName (str, optional): The spatial reference system name to use for the query.\n        bbox (str or gpd.GeoDataFrame, optional): The bounding box to apply to the query.\n            If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.\n        **kwargs: Additional parameters for the WFS query.\n\n    Returns:\n        dict: The result of the WFS query in JSON format.\n    \"\"\"\n    logger.debug(f\"Executing WFS query for item with id: {self.id}\")\n\n    if isinstance(bbox, gpd.GeoDataFrame):\n        logger.debug(\n            f\"Converting bbox GeoDataFrame to GeoJSON for item with id: {self.id}\"\n        )\n        bbox = gdf_to_bbox(bbox)\n\n    result = wfs_features.download_wfs_data(\n        url=self._wfs_url,\n        api_key=self._kserver._api_key,\n        typeNames=f\"{self.type}-{self.id}\",\n        cql_filter=cql_filter,\n        srsName=srsName or f\"EPSG:{self.epsg}\" if self.epsg else None,\n        bbox=bbox,\n        **kwargs,\n    )\n\n    return result\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.reset","title":"<code>reset()</code>","text":"<p>Resets the KVectorItem instance, clearing cached properties. This is useful for refreshing the item state.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Resets the KVectorItem instance, clearing cached properties.\n    This is useful for refreshing the item state.\n    \"\"\"\n    logger.info(f\"Resetting KVectorItem with id: {self.id}\")\n    self._supports_changesets = None\n    self._services = None\n    self._raw_json = None\n</code></pre>"},{"location":"reference/#pykaahma_linz.KVectorItem.KVectorItem.validate_export_request","title":"<code>validate_export_request(export_format, crs=None, extent=None, **kwargs)</code>","text":"<p>Validates the export request parameters for the item.</p> <p>Parameters:</p> Name Type Description Default <code>export_format</code> <code>str</code> <p>The format to export the item in.</p> required <code>crs</code> <code>str</code> <p>The coordinate reference system to use for the export.</p> <code>None</code> <code>extent</code> <code>dict</code> <p>The extent to use for the export. Should be a GeoJSON dictionary.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export request.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the export request is valid, False otherwise.</p> Source code in <code>src\\pykaahma_linz\\KVectorItem.py</code> <pre><code>def validate_export_request(\n    self,\n    export_format: str,\n    crs: str = None,\n    extent: dict = None,\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"\n    Validates the export request parameters for the item.\n\n    Parameters:\n        export_format (str): The format to export the item in.\n        crs (str, optional): The coordinate reference system to use for the export.\n        extent (dict, optional): The extent to use for the export. Should be a GeoJSON dictionary.\n        **kwargs: Additional parameters for the export request.\n\n    Returns:\n        bool: True if the export request is valid, False otherwise.\n    \"\"\"\n\n    export_format = self._resolve_export_format(export_format)\n\n    # log out all the input parameters including kwargs\n    logger.info(\n        f\"Validating export request for item with id: {self.id}, {export_format=}, {crs=}, {extent=},  {kwargs=}\"\n    )\n\n    return export_features.validate_export_params(\n        self._kserver._api_url,\n        self._kserver._api_key,\n        self.id,\n        self.type,\n        self.kind,\n        export_format,\n        crs,\n        extent,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/#pykaahma_linz.ContentManager.ContentManager","title":"<code>ContentManager</code>","text":"<p>Manages content for a KServer instance.</p> <p>Provides methods to search for, retrieve, and instantiate Koordinates items (layers, tables, etc.) based on their IDs or URLs.</p> <p>Attributes:</p> Name Type Description <code>_kserver</code> <code>KServer</code> <p>The KServer instance this manager is associated with.</p> Source code in <code>src\\pykaahma_linz\\ContentManager.py</code> <pre><code>class ContentManager:\n    \"\"\"\n    Manages content for a KServer instance.\n\n    Provides methods to search for, retrieve, and instantiate Koordinates items (layers, tables, etc.)\n    based on their IDs or URLs.\n\n    Attributes:\n        _kserver (KServer): The KServer instance this manager is associated with.\n    \"\"\"\n\n    def __init__(self, kserver: \"KServer\") -&gt; None:\n        \"\"\"\n        Initializes the ContentManager with a KServer instance.\n\n        Parameters:\n            kserver (KServer): The KServer instance to manage content for.\n\n        Returns:\n            None\n        \"\"\"\n        self._kserver = kserver\n\n    @property\n    def service_url(self) -&gt; str:\n        \"\"\"Returns the service URL of the KServer.\"\"\"\n        return self._kserver.service_url\n\n    @property\n    def api_url(self) -&gt; str:\n        \"\"\"Returns the API URL of the KServer.\"\"\"\n        return self._kserver.api_url\n\n    def _search_by_id(self, id: str) -&gt; dict:\n        \"\"\"\n        Searches for content by id in the KServer.\n\n        Parameters:\n            id (str): The id of the content to search for.\n\n        Returns:\n            dict: The content found in the KServer.\n        \"\"\"\n\n        # Example: https://data.linz.govt.nz/services/api/v1.x/data/?id=51571\n        url = f\"{self._kserver._api_url}data/?id={id}\"\n        response = requests.get(url)\n        response.raise_for_status()\n\n        return response.json()\n\n    def _get_item_details(self, url: str) -&gt; dict:\n        \"\"\"\n        Retrieves detailed information about a specific item.\n\n        Parameters:\n            url (str): The item URL to retrieve details for.\n\n        Returns:\n            dict: The detailed information of the item.\n        \"\"\"\n\n        response = requests.get(url)\n        response.raise_for_status()\n\n        return response.json()\n\n    def get(self, id: str) -&gt; dict:\n        \"\"\"\n        Retrieves content by id from the KServer.\n\n        Parameters:\n            id (str): The id of the content to retrieve.\n\n        Returns:\n            dict: The content retrieved from the KServer.\n\n        Raises:\n            KServerBadRequestError: If the content is not found or the request is invalid.\n            KUnknownItemTypeError: If the item kind is not supported.\n        \"\"\"\n\n        search_result = self._search_by_id(id)\n        if not search_result or \"error\" in search_result:\n            raise KServerBadRequestError(\n                f\"Content with id {id} not found or invalid request.\"\n            )\n        if len(search_result) == 0:\n            return None\n        elif len(search_result) &gt; 1:\n            raise KServerBadRequestError(\n                f\"Multiple contents found for id {id}. Please refine your search.\"\n            )\n\n        # Assuming the first item is the desired content\n        item_json = search_result[0]\n        if \"url\" not in item_json:\n            raise KServerError(f\"Item with id {id} does not have a URL.\")\n        item_details = self._get_item_details(item_json.get(\"url\", \"\"))\n\n        # Based on the kind of item, return the appropriate item class.\n        if item_details.get(\"kind\") == \"vector\":\n            item = KVectorItem(self._kserver, item_details)\n        elif item_details.get(\"kind\") == \"table\":\n            item = KTableItem(self._kserver, item_details)\n        else:\n            raise KUnknownItemTypeError(\n                f\"Unsupported item kind: {item_details.get('kind')}\"\n            )\n\n        return item\n</code></pre>"},{"location":"reference/#pykaahma_linz.ContentManager.ContentManager.api_url","title":"<code>api_url</code>  <code>property</code>","text":"<p>Returns the API URL of the KServer.</p>"},{"location":"reference/#pykaahma_linz.ContentManager.ContentManager.service_url","title":"<code>service_url</code>  <code>property</code>","text":"<p>Returns the service URL of the KServer.</p>"},{"location":"reference/#pykaahma_linz.ContentManager.ContentManager.__init__","title":"<code>__init__(kserver)</code>","text":"<p>Initializes the ContentManager with a KServer instance.</p> <p>Parameters:</p> Name Type Description Default <code>kserver</code> <code>KServer</code> <p>The KServer instance to manage content for.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\ContentManager.py</code> <pre><code>def __init__(self, kserver: \"KServer\") -&gt; None:\n    \"\"\"\n    Initializes the ContentManager with a KServer instance.\n\n    Parameters:\n        kserver (KServer): The KServer instance to manage content for.\n\n    Returns:\n        None\n    \"\"\"\n    self._kserver = kserver\n</code></pre>"},{"location":"reference/#pykaahma_linz.ContentManager.ContentManager.get","title":"<code>get(id)</code>","text":"<p>Retrieves content by id from the KServer.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the content to retrieve.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The content retrieved from the KServer.</p> <p>Raises:</p> Type Description <code>KServerBadRequestError</code> <p>If the content is not found or the request is invalid.</p> <code>KUnknownItemTypeError</code> <p>If the item kind is not supported.</p> Source code in <code>src\\pykaahma_linz\\ContentManager.py</code> <pre><code>def get(self, id: str) -&gt; dict:\n    \"\"\"\n    Retrieves content by id from the KServer.\n\n    Parameters:\n        id (str): The id of the content to retrieve.\n\n    Returns:\n        dict: The content retrieved from the KServer.\n\n    Raises:\n        KServerBadRequestError: If the content is not found or the request is invalid.\n        KUnknownItemTypeError: If the item kind is not supported.\n    \"\"\"\n\n    search_result = self._search_by_id(id)\n    if not search_result or \"error\" in search_result:\n        raise KServerBadRequestError(\n            f\"Content with id {id} not found or invalid request.\"\n        )\n    if len(search_result) == 0:\n        return None\n    elif len(search_result) &gt; 1:\n        raise KServerBadRequestError(\n            f\"Multiple contents found for id {id}. Please refine your search.\"\n        )\n\n    # Assuming the first item is the desired content\n    item_json = search_result[0]\n    if \"url\" not in item_json:\n        raise KServerError(f\"Item with id {id} does not have a URL.\")\n    item_details = self._get_item_details(item_json.get(\"url\", \"\"))\n\n    # Based on the kind of item, return the appropriate item class.\n    if item_details.get(\"kind\") == \"vector\":\n        item = KVectorItem(self._kserver, item_details)\n    elif item_details.get(\"kind\") == \"table\":\n        item = KTableItem(self._kserver, item_details)\n    else:\n        raise KUnknownItemTypeError(\n            f\"Unsupported item kind: {item_details.get('kind')}\"\n        )\n\n    return item\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.DownloadResult","title":"<code>DownloadResult</code>  <code>dataclass</code>","text":"<p>Contains metadata about a completed file download from a Koordinates export job.</p> <p>This class is returned by the JobResult.download and JobResult.download_async methods, providing detailed information about the downloaded file and its context.</p> <p>Attributes:</p> Name Type Description <code>folder</code> <code>str</code> <p>The directory where the file was saved.</p> <code>filename</code> <code>str</code> <p>The name of the downloaded file (without path).</p> <code>file_path</code> <code>str</code> <p>The full path to the downloaded file.</p> <code>file_size_bytes</code> <code>int</code> <p>The size of the downloaded file in bytes.</p> <code>download_url</code> <code>str</code> <p>The original download URL provided by the job.</p> <code>final_url</code> <code>str</code> <p>The final resolved URL after redirects (e.g., S3 location).</p> <code>job_id</code> <code>int</code> <p>The unique identifier of the export job.</p> <code>completed_at</code> <code>float</code> <p>The timestamp (seconds since epoch) when the download completed.</p> <code>checksum</code> <code>str | None</code> <p>The SHA256 checksum of the downloaded file, or None if unavailable.</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>@dataclass\nclass DownloadResult:\n    \"\"\"\n    Contains metadata about a completed file download from a Koordinates export job.\n\n    This class is returned by the JobResult.download and JobResult.download_async methods,\n    providing detailed information about the downloaded file and its context.\n\n    Attributes:\n        folder (str): The directory where the file was saved.\n        filename (str): The name of the downloaded file (without path).\n        file_path (str): The full path to the downloaded file.\n        file_size_bytes (int): The size of the downloaded file in bytes.\n        download_url (str): The original download URL provided by the job.\n        final_url (str): The final resolved URL after redirects (e.g., S3 location).\n        job_id (int): The unique identifier of the export job.\n        completed_at (float): The timestamp (seconds since epoch) when the download completed.\n        checksum (str | None): The SHA256 checksum of the downloaded file, or None if unavailable.\n    \"\"\"\n\n    folder: str\n    filename: str\n    file_path: str\n    file_size_bytes: int\n    download_url: str\n    final_url: str\n    job_id: int\n    completed_at: float\n    checksum: str | None = None\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult","title":"<code>JobResult</code>","text":"<p>Represents the result of an asynchronous export or processing job.</p> <p>Provides methods to poll for job completion, retrieve job status, and download results. The download and download_async methods return a DownloadResult object containing detailed metadata about the downloaded file. Download metadata is also stored as attributes on the JobResult instance after a successful download.</p> <p>Attributes:</p> Name Type Description <code>_initial_payload</code> <code>dict</code> <p>The initial job payload from the API.</p> <code>_job_url</code> <code>str</code> <p>The URL to poll for job status.</p> <code>_id</code> <code>int</code> <p>The unique identifier of the job.</p> <code>_poll_interval</code> <code>int</code> <p>Polling interval in seconds.</p> <code>_timeout</code> <code>int</code> <p>Maximum time to wait for job completion in seconds.</p> <code>_last_response</code> <code>dict</code> <p>The most recent job status response.</p> <code>_kserver</code> <code>KServer</code> <p>The KServer instance associated with this job.</p> <code>#</code> <code>Populated after download</code> <code>download_folder</code> <code>str</code> <p>The directory where the file was saved.</p> <code>download_filename</code> <code>str</code> <p>The name of the downloaded file.</p> <code>download_file_path</code> <code>str</code> <p>The full path to the downloaded file.</p> <code>download_file_size_bytes</code> <code>int</code> <p>The size of the downloaded file in bytes.</p> <code>download_completed_at</code> <code>float</code> <p>The timestamp when the download completed.</p> <code>download_resolved_url</code> <code>str</code> <p>The final resolved URL after redirects.</p> <code>download_checksum</code> <code>str | None</code> <p>The SHA256 checksum of the downloaded file.</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>class JobResult:\n    \"\"\"\n    Represents the result of an asynchronous export or processing job.\n\n    Provides methods to poll for job completion, retrieve job status, and download results.\n    The download and download_async methods return a DownloadResult object containing\n    detailed metadata about the downloaded file. Download metadata is also stored as\n    attributes on the JobResult instance after a successful download.\n\n    Attributes:\n        _initial_payload (dict): The initial job payload from the API.\n        _job_url (str): The URL to poll for job status.\n        _id (int): The unique identifier of the job.\n        _poll_interval (int): Polling interval in seconds.\n        _timeout (int): Maximum time to wait for job completion in seconds.\n        _last_response (dict): The most recent job status response.\n        _kserver (KServer): The KServer instance associated with this job.\n\n        # Populated after download:\n        download_folder (str): The directory where the file was saved.\n        download_filename (str): The name of the downloaded file.\n        download_file_path (str): The full path to the downloaded file.\n        download_file_size_bytes (int): The size of the downloaded file in bytes.\n        download_completed_at (float): The timestamp when the download completed.\n        download_resolved_url (str): The final resolved URL after redirects.\n        download_checksum (str | None): The SHA256 checksum of the downloaded file.\n    \"\"\"\n\n    def __init__(\n        self,\n        payload: dict,\n        kserver: \"KServer\",\n        poll_interval: int = 10,\n        timeout: int = 300,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the JobResult instance.\n\n        Parameters:\n            payload (dict): The job payload, typically from an API response.\n            kserver (KServer): The KServer instance associated with this job.\n            poll_interval (int, optional): The interval in seconds to poll the job status. Default is 10 seconds.\n            timeout (int, optional): The maximum time in seconds to wait for the job to complete. Default is 300 seconds.\n\n        Returns:\n            None\n        \"\"\"\n        self._initial_payload = payload\n        self._job_url = payload[\"url\"]\n        self._id = payload[\"id\"]\n        self._poll_interval = poll_interval\n        self._timeout = timeout\n        self._last_response = payload\n        self._kserver = kserver\n\n    @property\n    def id(self) -&gt; int:\n        return self._id\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Returns the name of the job.\"\"\"\n        return self._last_response.get(\"name\", \"unknown_name\")\n\n    @property\n    def download_url(self) -&gt; str | None:\n        return self._last_response.get(\"download_url\")\n\n    @property\n    def status(self) -&gt; str:\n        self._refresh_sync()\n        return self._last_response.get(\"state\")\n\n    @property\n    def progress(self) -&gt; float | None:\n        \"\"\"Returns the progress of the job as a percentage.\"\"\"\n        return self._last_response.get(\"progress\", None)\n\n    @property\n    def created_at(self) -&gt; str | None:\n        \"\"\"Returns the creation time of the job.\"\"\"\n        return self._last_response.get(\"created_at\", None)\n\n    def to_dict(self) -&gt; dict:\n        return self._last_response\n\n    def __str__(self) -&gt; str:\n        self._refresh_sync()\n        return (\n            f\"JobResult(id={self.id}, name='{self.name}', \"\n            f\"status='{self._last_response.get('state')}', \"\n            f\"progress={self.progress})\"\n        )\n\n    def _refresh_sync(self) -&gt; None:\n        \"\"\"Refresh job status using synchronous HTTP via KServer.\"\"\"\n        self._last_response = self._kserver.get(self._job_url)\n\n    async def _refresh_async(self) -&gt; None:\n        \"\"\"Refresh job status using asynchronous HTTP via KServer.\"\"\"\n        self._last_response = await self._kserver.async_get(self._job_url)\n\n    def output(self) -&gt; dict:\n        \"\"\"\n        Blocking: Waits for the job to complete synchronously.\n\n        Returns:\n            dict: The final job response after completion.\n\n        Raises:\n            TimeoutError: If the job does not complete within the timeout.\n            RuntimeError: If the job fails or is cancelled.\n        \"\"\"\n        start = time.time()\n        # timeout the while loop if it takes more than twenty minutes\n        # to complete\n        max_time = 1200  # 20 minutes in seconds\n\n        while True and time.time() - start &lt; max_time:\n            self._refresh_sync()\n            state = self._last_response.get(\"state\")\n            if state in (\"complete\", \"failed\", \"cancelled\"):\n                break\n\n            if (time.time() - start) &gt; self._timeout:\n                raise TimeoutError(\n                    f\"Export job {self._id} did not complete within timeout.\"\n                )\n\n            time.sleep(self._poll_interval)\n\n        if self._last_response.get(\"state\") != \"complete\":\n            raise RuntimeError(\n                f\"Export job {self._id} failed with state: {self._last_response.get('state')}\"\n            )\n\n        return self._last_response\n\n    async def output_async(self) -&gt; dict:\n        \"\"\"\n        Non-blocking: Waits for the job to complete asynchronously.\n\n        Returns:\n            dict: The final job response after completion.\n\n        Raises:\n            TimeoutError: If the job does not complete within the timeout.\n            RuntimeError: If the job fails or is cancelled.\n        \"\"\"\n        start = asyncio.get_event_loop().time()\n        max_time = 600  # 10 minutes in seconds\n        while True and (asyncio.get_event_loop().time() - start &lt; max_time):\n            await self._refresh_async()\n            state = self._last_response.get(\"state\")\n            logger.debug(f\"Job {self._id} state: {state} progress: {self.progress}\")\n            if state in (\"complete\", \"failed\", \"cancelled\"):\n                break\n\n            if (asyncio.get_event_loop().time() - start) &gt; self._timeout:\n                raise TimeoutError(\n                    f\"Export job {self._id} did not complete within timeout.\"\n                )\n\n            await asyncio.sleep(self._poll_interval)\n\n        if self._last_response.get(\"state\") != \"complete\":\n            raise RuntimeError(\n                f\"Export job {self._id} failed with state: {self._last_response.get('state')}\"\n            )\n\n        return self._last_response\n\n    def download(self, folder: str, file_name: str | None = None) -&gt; DownloadResult:\n        \"\"\"\n        Waits for job to finish, then downloads the file synchronously.\n\n        Parameters:\n            folder (str): The folder where the file will be saved.\n            file_name (str, optional): The name of the file to save. If None, uses job name.\n\n        Returns:\n            DownloadResult: An object containing details about the downloaded file.\n\n        Raises:\n            ValueError: If the download URL is not available.\n        \"\"\"\n\n        self.output()  # ensure job is complete\n        if not self.download_url:\n            raise ValueError(\n                \"Download URL not available. Job may not have completed successfully.\"\n            )\n\n        file_name = f\"{file_name}.zip\" if file_name else f\"{self.name}.zip\"\n        file_path = os.path.join(folder, file_name)\n        if not os.path.exists(folder):\n            os.makedirs(folder, exist_ok=True)\n\n        headers = {\"Authorization\": f\"key {self._kserver._api_key}\"}\n\n        with httpx.Client(follow_redirects=True) as client:\n            resp = client.get(self.download_url, headers=headers, follow_redirects=True)\n            resp.raise_for_status()\n            final_url = str(resp.url)\n\n            with client.stream(\"GET\", final_url) as r, open(file_path, \"wb\") as f:\n                r.raise_for_status()\n                for chunk in r.iter_bytes():\n                    f.write(chunk)\n\n        file_size_bytes = os.path.getsize(file_path)\n        checksum = None\n        try:\n            with open(file_path, \"rb\") as f:\n                checksum = hashlib.sha256(f.read()).hexdigest()\n        except Exception:\n            pass\n        completed_at = time.time()\n\n        # Set as attributes on the JobResult instance\n        self.download_folder = folder\n        self.download_filename = file_name\n        self.download_file_path = file_path\n        self.download_file_size_bytes = file_size_bytes\n        self.download_completed_at = completed_at\n        self.download_resolved_url = final_url\n        self.download_checksum = checksum\n\n        return DownloadResult(\n            folder=folder,\n            filename=file_name,\n            file_path=file_path,\n            file_size_bytes=file_size_bytes,\n            download_url=self.download_url,\n            final_url=final_url,\n            job_id=self._id,\n            completed_at=completed_at,\n            checksum=checksum,\n        )\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.created_at","title":"<code>created_at</code>  <code>property</code>","text":"<p>Returns the creation time of the job.</p>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name of the job.</p>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.progress","title":"<code>progress</code>  <code>property</code>","text":"<p>Returns the progress of the job as a percentage.</p>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.__init__","title":"<code>__init__(payload, kserver, poll_interval=10, timeout=300)</code>","text":"<p>Initializes the JobResult instance.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>dict</code> <p>The job payload, typically from an API response.</p> required <code>kserver</code> <code>KServer</code> <p>The KServer instance associated with this job.</p> required <code>poll_interval</code> <code>int</code> <p>The interval in seconds to poll the job status. Default is 10 seconds.</p> <code>10</code> <code>timeout</code> <code>int</code> <p>The maximum time in seconds to wait for the job to complete. Default is 300 seconds.</p> <code>300</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>def __init__(\n    self,\n    payload: dict,\n    kserver: \"KServer\",\n    poll_interval: int = 10,\n    timeout: int = 300,\n) -&gt; None:\n    \"\"\"\n    Initializes the JobResult instance.\n\n    Parameters:\n        payload (dict): The job payload, typically from an API response.\n        kserver (KServer): The KServer instance associated with this job.\n        poll_interval (int, optional): The interval in seconds to poll the job status. Default is 10 seconds.\n        timeout (int, optional): The maximum time in seconds to wait for the job to complete. Default is 300 seconds.\n\n    Returns:\n        None\n    \"\"\"\n    self._initial_payload = payload\n    self._job_url = payload[\"url\"]\n    self._id = payload[\"id\"]\n    self._poll_interval = poll_interval\n    self._timeout = timeout\n    self._last_response = payload\n    self._kserver = kserver\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.download","title":"<code>download(folder, file_name=None)</code>","text":"<p>Waits for job to finish, then downloads the file synchronously.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>The folder where the file will be saved.</p> required <code>file_name</code> <code>str</code> <p>The name of the file to save. If None, uses job name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DownloadResult</code> <code>DownloadResult</code> <p>An object containing details about the downloaded file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the download URL is not available.</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>def download(self, folder: str, file_name: str | None = None) -&gt; DownloadResult:\n    \"\"\"\n    Waits for job to finish, then downloads the file synchronously.\n\n    Parameters:\n        folder (str): The folder where the file will be saved.\n        file_name (str, optional): The name of the file to save. If None, uses job name.\n\n    Returns:\n        DownloadResult: An object containing details about the downloaded file.\n\n    Raises:\n        ValueError: If the download URL is not available.\n    \"\"\"\n\n    self.output()  # ensure job is complete\n    if not self.download_url:\n        raise ValueError(\n            \"Download URL not available. Job may not have completed successfully.\"\n        )\n\n    file_name = f\"{file_name}.zip\" if file_name else f\"{self.name}.zip\"\n    file_path = os.path.join(folder, file_name)\n    if not os.path.exists(folder):\n        os.makedirs(folder, exist_ok=True)\n\n    headers = {\"Authorization\": f\"key {self._kserver._api_key}\"}\n\n    with httpx.Client(follow_redirects=True) as client:\n        resp = client.get(self.download_url, headers=headers, follow_redirects=True)\n        resp.raise_for_status()\n        final_url = str(resp.url)\n\n        with client.stream(\"GET\", final_url) as r, open(file_path, \"wb\") as f:\n            r.raise_for_status()\n            for chunk in r.iter_bytes():\n                f.write(chunk)\n\n    file_size_bytes = os.path.getsize(file_path)\n    checksum = None\n    try:\n        with open(file_path, \"rb\") as f:\n            checksum = hashlib.sha256(f.read()).hexdigest()\n    except Exception:\n        pass\n    completed_at = time.time()\n\n    # Set as attributes on the JobResult instance\n    self.download_folder = folder\n    self.download_filename = file_name\n    self.download_file_path = file_path\n    self.download_file_size_bytes = file_size_bytes\n    self.download_completed_at = completed_at\n    self.download_resolved_url = final_url\n    self.download_checksum = checksum\n\n    return DownloadResult(\n        folder=folder,\n        filename=file_name,\n        file_path=file_path,\n        file_size_bytes=file_size_bytes,\n        download_url=self.download_url,\n        final_url=final_url,\n        job_id=self._id,\n        completed_at=completed_at,\n        checksum=checksum,\n    )\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.output","title":"<code>output()</code>","text":"<p>Blocking: Waits for the job to complete synchronously.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The final job response after completion.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If the job does not complete within the timeout.</p> <code>RuntimeError</code> <p>If the job fails or is cancelled.</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>def output(self) -&gt; dict:\n    \"\"\"\n    Blocking: Waits for the job to complete synchronously.\n\n    Returns:\n        dict: The final job response after completion.\n\n    Raises:\n        TimeoutError: If the job does not complete within the timeout.\n        RuntimeError: If the job fails or is cancelled.\n    \"\"\"\n    start = time.time()\n    # timeout the while loop if it takes more than twenty minutes\n    # to complete\n    max_time = 1200  # 20 minutes in seconds\n\n    while True and time.time() - start &lt; max_time:\n        self._refresh_sync()\n        state = self._last_response.get(\"state\")\n        if state in (\"complete\", \"failed\", \"cancelled\"):\n            break\n\n        if (time.time() - start) &gt; self._timeout:\n            raise TimeoutError(\n                f\"Export job {self._id} did not complete within timeout.\"\n            )\n\n        time.sleep(self._poll_interval)\n\n    if self._last_response.get(\"state\") != \"complete\":\n        raise RuntimeError(\n            f\"Export job {self._id} failed with state: {self._last_response.get('state')}\"\n        )\n\n    return self._last_response\n</code></pre>"},{"location":"reference/#pykaahma_linz.JobResult.JobResult.output_async","title":"<code>output_async()</code>  <code>async</code>","text":"<p>Non-blocking: Waits for the job to complete asynchronously.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The final job response after completion.</p> <p>Raises:</p> Type Description <code>TimeoutError</code> <p>If the job does not complete within the timeout.</p> <code>RuntimeError</code> <p>If the job fails or is cancelled.</p> Source code in <code>src\\pykaahma_linz\\JobResult.py</code> <pre><code>async def output_async(self) -&gt; dict:\n    \"\"\"\n    Non-blocking: Waits for the job to complete asynchronously.\n\n    Returns:\n        dict: The final job response after completion.\n\n    Raises:\n        TimeoutError: If the job does not complete within the timeout.\n        RuntimeError: If the job fails or is cancelled.\n    \"\"\"\n    start = asyncio.get_event_loop().time()\n    max_time = 600  # 10 minutes in seconds\n    while True and (asyncio.get_event_loop().time() - start &lt; max_time):\n        await self._refresh_async()\n        state = self._last_response.get(\"state\")\n        logger.debug(f\"Job {self._id} state: {state} progress: {self.progress}\")\n        if state in (\"complete\", \"failed\", \"cancelled\"):\n            break\n\n        if (asyncio.get_event_loop().time() - start) &gt; self._timeout:\n            raise TimeoutError(\n                f\"Export job {self._id} did not complete within timeout.\"\n            )\n\n        await asyncio.sleep(self._poll_interval)\n\n    if self._last_response.get(\"state\") != \"complete\":\n        raise RuntimeError(\n            f\"Export job {self._id} failed with state: {self._last_response.get('state')}\"\n        )\n\n    return self._last_response\n</code></pre>"},{"location":"reference/#feature-utilities","title":"Feature Utilities","text":"<p>The following are helper features used internally by the classes to interact with the Koordinates API and perform data conversions.  </p>"},{"location":"reference/#pykaahma_linz.features.Conversion.gdf_to_bbox","title":"<code>gdf_to_bbox(gdf)</code>","text":"<p>Convert a GeoDataFrame to a bounding box string.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame containing geometries.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A bounding box string in the format \"XMin,YMin,XMax,YMax,EPSG:4326\".</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the GeoDataFrame is empty or does not contain valid geometries.</p> Source code in <code>src\\pykaahma_linz\\features\\Conversion.py</code> <pre><code>def gdf_to_bbox(gdf: gpd.GeoDataFrame) -&gt; str:\n    \"\"\"\n    Convert a GeoDataFrame to a bounding box string.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame): A GeoDataFrame containing geometries.\n\n    Returns:\n        str: A bounding box string in the format \"XMin,YMin,XMax,YMax,EPSG:4326\".\n\n    Raises:\n        ValueError: If the GeoDataFrame is empty or does not contain valid geometries.\n    \"\"\"\n    if gdf.empty:\n        raise ValueError(\"GeoDataFrame must contain at least one geometry.\")\n\n    if not all(gdf.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])):\n        raise ValueError(\n            \"GeoDataFrame must contain only Polygon or MultiPolygon geometries.\"\n        )\n\n    # Ensure the GeoDataFrame is in EPSG:4326\n    if gdf.crs is None:\n        gdf.set_crs(epsg=4326, inplace=True)\n    elif gdf.crs.to_epsg() != 4326:\n        gdf = gdf.to_crs(epsg=4326)\n\n    # Calculate the bounding box\n    bounds = gdf.total_bounds  # returns (minx, miny, maxx, maxy)\n    bbox_string = f\"{bounds[0]},{bounds[1]},{bounds[2]},{bounds[3]},EPSG:4326\"\n\n    return bbox_string\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.Conversion.gdf_to_single_polygon_geojson","title":"<code>gdf_to_single_polygon_geojson(gdf)</code>","text":"<p>Convert a GeoDataFrame to a single GeoJSON polygon geometry object.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>A GeoDataFrame containing polygon geometries.</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>dict or None: A GeoJSON polygon geometry object or None if the GeoDataFrame is empty.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the GeoDataFrame is empty or contains non-polygon geometries.</p> Source code in <code>src\\pykaahma_linz\\features\\Conversion.py</code> <pre><code>def gdf_to_single_polygon_geojson(gdf: gpd.GeoDataFrame) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Convert a GeoDataFrame to a single GeoJSON polygon geometry object.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame): A GeoDataFrame containing polygon geometries.\n\n    Returns:\n        dict or None: A GeoJSON polygon geometry object or None if the GeoDataFrame is empty.\n\n    Raises:\n        ValueError: If the GeoDataFrame is empty or contains non-polygon geometries.\n    \"\"\"\n    if gdf.empty:\n        raise ValueError(\"GeoDataFrame must at least one Polygon geometry.\")\n\n    if not all(gdf.geometry.type == \"Polygon\"):\n        raise ValueError(\"GeoDataFrame must contain only Polygon geometries.\")\n\n    # convert crs to EPSG:4326 if not already\n    if gdf.crs is None:\n        gdf.set_crs(epsg=4326, inplace=True)\n    elif gdf.crs.to_epsg() != 4326:\n        gdf = gdf.to_crs(epsg=4326)\n\n    # Union all geometries into a single geometry\n    single_geometry = gdf.unary_union\n    if single_geometry.is_empty:\n        raise ValueError(\"Resulting geometry is empty after union.\")\n\n    geom = single_geometry.__geo_interface__\n\n    logger.info(geom)\n\n    return geom\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.Conversion.geojson_to_gdf","title":"<code>geojson_to_gdf(geojson, epsg, fields=None)</code>","text":"<p>Convert GeoJSON features to a GeoDataFrame with enforced data types.</p> <p>Parameters:</p> Name Type Description Default <code>geojson</code> <code>dict or list</code> <p>Either a GeoJSON FeatureCollection (dict) or a list of GeoJSON features (dicts).</p> required <code>epsg</code> <code>str or int</code> <p>Coordinate Reference System (e.g., \"4326\").</p> required <code>fields</code> <code>list</code> <p>A list of dictionaries specifying field names and their desired data types.</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: A GeoDataFrame with the specified CRS and column types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the geojson input is invalid.</p> Source code in <code>src\\pykaahma_linz\\features\\Conversion.py</code> <pre><code>def geojson_to_gdf(\n    geojson: dict[str, Any] | list[dict[str, Any]],\n    epsg: str | int,\n    fields: list[dict[str, str]] | None = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Convert GeoJSON features to a GeoDataFrame with enforced data types.\n\n    Parameters:\n        geojson (dict or list): Either a GeoJSON FeatureCollection (dict) or a list of GeoJSON features (dicts).\n        epsg (str or int): Coordinate Reference System (e.g., \"4326\").\n        fields (list, optional): A list of dictionaries specifying field names and their desired data types.\n\n    Returns:\n        gpd.GeoDataFrame: A GeoDataFrame with the specified CRS and column types.\n\n    Raises:\n        ValueError: If the geojson input is invalid.\n    \"\"\"\n\n    logger.debug(\"Converting GeoJSON to GeoDataFrame...\")\n\n    # if the geosjon is None, return an empty GeoDataFrame\n    if geojson is None:\n        logger.warning(\"Received None as geojson input, returning empty GeoDataFrame.\")\n        return gpd.GeoDataFrame(columns=[], geometry=[])\n\n    # Extract features from a FeatureCollection if needed\n    if isinstance(geojson, dict) and geojson.get(\"type\") == \"FeatureCollection\":\n        features = geojson.get(\"features\", [])\n    elif isinstance(geojson, list):\n        features = geojson\n    else:\n        raise ValueError(\n            \"Invalid geojson input. Expected a FeatureCollection or list of features.\"\n        )\n\n    # Flatten properties and extract geometry\n    records = []\n    geometries = []\n    for feature in features:\n        props = feature.get(\"properties\", {})\n        geom = feature.get(\"geometry\")\n        records.append(props)\n        geometries.append(shape(geom) if geom else None)\n\n    # Create GeoDataFrame\n    crs = f\"EPSG:{epsg}\"\n    df = pd.DataFrame(records)\n    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs=crs)\n\n    # Apply data type mapping\n    if fields and False:\n        for field in fields:\n            col = field.get(\"name\")\n            dtype = field.get(\"type\").lower()\n            if dtype == \"geometry\":\n                continue  # Skip geometry fields as they are already handled\n            if col in gdf.columns:\n                try:\n                    if dtype in [\"int\", \"bigint\", \"integer\", \"int32\", \"int64\"]:\n                        gdf[col] = (\n                            pd.to_numeric(gdf[col], errors=\"coerce\")\n                            .fillna(0)\n                            .astype(\"int32\")\n                        )\n                    elif dtype in [\"float\", \"double\"]:\n                        gdf[col] = pd.to_numeric(gdf[col], errors=\"coerce\")\n                    elif dtype in [\"str\", \"string\"]:\n                        gdf[col] = gdf[col].astype(str)\n                    elif dtype == \"bool\":\n                        gdf[col] = gdf[col].astype(bool)\n                    else:\n                        logger.warning(\n                            f\"Unsupported data type '{dtype}' for column '{col}'. Skipping conversion.\"\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f\"Failed to convert column '{col}' to {dtype}: {e}\"\n                    )\n    return gdf\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.Conversion.json_to_df","title":"<code>json_to_df(json, fields=None)</code>","text":"<p>Convert JSON features to a DataFrame with enforced data types.</p> <p>Parameters:</p> Name Type Description Default <code>json</code> <code>dict or list</code> <p>Either a JSON FeatureCollection (dict) or a list of JSON features (dicts).</p> required <code>fields</code> <code>list</code> <p>A list of dictionaries specifying field names and their desired data types.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame with the specified column types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the json input is invalid.</p> Source code in <code>src\\pykaahma_linz\\features\\Conversion.py</code> <pre><code>def json_to_df(\n    json: dict[str, Any] | list[dict[str, Any]],\n    fields: list[dict[str, str]] | None = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert JSON features to a DataFrame with enforced data types.\n\n    Parameters:\n        json (dict or list): Either a JSON FeatureCollection (dict) or a list of JSON features (dicts).\n        fields (list, optional): A list of dictionaries specifying field names and their desired data types.\n\n    Returns:\n        pd.DataFrame: A DataFrame with the specified column types.\n\n    Raises:\n        ValueError: If the json input is invalid.\n    \"\"\"\n\n    logger.debug(\"Converting JSON to DataFrame...\")\n\n    # Extract features from a FeatureCollection if needed\n    if isinstance(json, dict) and json.get(\"type\") == \"FeatureCollection\":\n        features = json.get(\"features\", [])\n    elif isinstance(json, list):\n        features = json\n    else:\n        raise ValueError(\n            \"Invalid json input. Expected a FeatureCollection or list of features.\"\n        )\n\n    # Flatten properties and extract geometry\n    records = []\n    for feature in features:\n        props = feature.get(\"properties\", {})\n        records.append(props)\n    df = pd.DataFrame(records)\n\n    # Apply data type mapping\n    if fields and False:\n        for field in fields:\n            col = field.get(\"name\")\n            dtype = field.get(\"type\").lower()\n            if col in df.columns:\n                try:\n                    if dtype in [\"int\", \"bigint\", \"integer\", \"int32\", \"int64\"]:\n                        df[col] = (\n                            pd.to_numeric(df[col], errors=\"coerce\")\n                            .fillna(0)\n                            .astype(\"int32\")\n                        )\n                    elif dtype in [\"float\", \"double\"]:\n                        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n                    elif dtype in [\"str\", \"string\"]:\n                        df[col] = df[col].astype(str)\n                    elif dtype == \"bool\":\n                        df[col] = df[col].astype(bool)\n                    else:\n                        logger.warning(\n                            f\"Unsupported data type '{dtype}' for column '{col}'. Skipping conversion.\"\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f\"Failed to convert column '{col}' to {dtype}: {e}\"\n                    )\n\n    return df\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.wfs.WfsBadRequestError","title":"<code>WfsBadRequestError</code>","text":"<p>               Bases: <code>WfsDownloaderError</code></p> <p>Raised when a 400 Bad Request is returned from the WFS service.</p> Source code in <code>src\\pykaahma_linz\\features\\wfs.py</code> <pre><code>class WfsBadRequestError(WfsDownloaderError):\n    \"\"\"Raised when a 400 Bad Request is returned from the WFS service.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.wfs.WfsDownloaderError","title":"<code>WfsDownloaderError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for errors encountered during WFS data download.</p> Source code in <code>src\\pykaahma_linz\\features\\wfs.py</code> <pre><code>class WfsDownloaderError(Exception):\n    \"\"\"Custom exception for errors encountered during WFS data download.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.wfs.download_wfs_data","title":"<code>download_wfs_data(url, typeNames, api_key, srsName=DEFAULT_SRSNAME, cql_filter=None, count=None, page_count=DEFAULT_PAGE_COUNT, **other_wfs_params)</code>","text":"<p>Downloads features from a WFS service, handling pagination and retries.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The base URL of the WFS service (e.g., \"https://data.linz.govt.nz/services/wfs\").</p> required <code>typeNames</code> <code>str</code> <p>The typeNames for the desired layer (e.g., \"layer-12345\").</p> required <code>api_key</code> <code>str</code> <p>API key.</p> required <code>srsName</code> <code>str</code> <p>Spatial Reference System name (e.g., \"EPSG:2193\"). Defaults to \"EPSG:2193\".</p> <code>DEFAULT_SRSNAME</code> <code>cql_filter</code> <code>str</code> <p>CQL filter to apply to the WFS request. Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>Maximum number of features to fetch.</p> <code>None</code> <code>page_count</code> <code>int</code> <p>Number of features per page request. Defaults to DEFAULT_PAGE_COUNT.</p> <code>DEFAULT_PAGE_COUNT</code> <code>**other_wfs_params</code> <code>Any</code> <p>Additional WFS parameters.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A GeoJSON FeatureCollection-like dictionary containing all fetched features.</p> <p>Raises:</p> Type Description <code>WfsDownloaderError</code> <p>If the API key or layer_id is missing, or if data fetching fails after all retries.</p> Source code in <code>src\\pykaahma_linz\\features\\wfs.py</code> <pre><code>def download_wfs_data(\n    url: str,\n    typeNames: str,\n    api_key: str,\n    srsName: str = DEFAULT_SRSNAME,\n    cql_filter: str = None,\n    count=None,\n    page_count: int = DEFAULT_PAGE_COUNT,\n    **other_wfs_params: Any,\n) -&gt; dict:\n    \"\"\"\n    Downloads features from a WFS service, handling pagination and retries.\n\n    Parameters:\n        url (str): The base URL of the WFS service (e.g., \"https://data.linz.govt.nz/services/wfs\").\n        typeNames (str): The typeNames for the desired layer (e.g., \"layer-12345\").\n        api_key (str): API key.\n        srsName (str, optional): Spatial Reference System name (e.g., \"EPSG:2193\"). Defaults to \"EPSG:2193\".\n        cql_filter (str, optional): CQL filter to apply to the WFS request. Defaults to None.\n        count (int, optional): Maximum number of features to fetch.\n        page_count (int, optional): Number of features per page request. Defaults to DEFAULT_PAGE_COUNT.\n        **other_wfs_params: Additional WFS parameters.\n\n    Returns:\n        dict: A GeoJSON FeatureCollection-like dictionary containing all fetched features.\n\n    Raises:\n        WfsDownloaderError: If the API key or layer_id is missing, or if data fetching fails after all retries.\n    \"\"\"\n\n    if not api_key:\n        raise WfsDownloaderError(\"API key must be provided.\")\n    if not typeNames:\n        raise WfsDownloaderError(\"Typenames (i.e. layer id) must be provided.\")\n\n    headers = {\"Authorization\": f\"key {api_key}\"}\n    all_features = []\n    start_index = 0\n    page_count = min(page_count, count) if count is not None else page_count\n    crs_info = None\n    total_features_service_reported = None\n\n    # The final result to return\n    result = None\n\n    logger.debug(f\"Starting WFS data download for typeNames: '{typeNames}'\")\n    if cql_filter:\n        logger.debug(f\"Using CQL filter: {cql_filter}\")\n\n    pages_fetched = 0  # Track number of pages fetched to prevent infinite loops\n    while pages_fetched &lt; MAX_PAGE_FETCHES:\n        logger.debug(f\"Pages fetched: {pages_fetched} of max: {MAX_PAGE_FETCHES}\")\n        pages_fetched += 1\n        wfs_request_params = {\n            \"service\": DEFAULT_WFS_SERVICE,\n            \"version\": DEFAULT_WFS_VERSION,\n            \"request\": DEFAULT_WFS_REQUEST,\n            \"outputFormat\": DEFAULT_WFS_OUTPUT_FORMAT,\n            \"typeNames\": typeNames,\n            \"srsName\": srsName,\n            \"startIndex\": start_index,\n            \"count\": page_count,\n            \"cql_filter\": cql_filter,\n            **{k: v for k, v in other_wfs_params.items()},\n        }\n\n        try:\n            page_data = _fetch_single_page_data(url, headers, wfs_request_params)\n        except WfsBadRequestError as e:\n            logger.error(f\"### Bad request error: {e}\")\n            raise\n        except (\n            RetryError\n        ) as e:  # This occurs if tenacity gives up after all retry attempts\n            # The original exception from the last attempt is available in e.last_attempt.exception()\n            last_exception = e.last_attempt.exception() if e.last_attempt else e\n            logger.error(\n                f\"All retries failed for '{typeNames}' at startIndex {start_index}. Last error: {last_exception}\"\n            )\n            raise WfsDownloaderError(\n                f\"Failed to download WFS data for '{typeNames}' after multiple retries. Last error: {last_exception}\"\n            ) from last_exception\n        except (\n            WfsDownloaderError\n        ):  # Raised directly by _fetch_single_page_data for non-retryable issues\n            raise  # Propagate the error\n        except Exception as e:\n            logger.error(\n                f\"Unexpected error for '{typeNames}' at startIndex {start_index}: {e}\"\n            )\n            raise WfsDownloaderError(\n                f\"Failed to download WFS data for '{typeNames}' due to unexpected error: {e}\"\n            ) from e\n\n        if not page_data or not isinstance(page_data, dict):\n            logger.warning(\n                f\"Received empty or invalid data for '{typeNames}' at startIndex {start_index}. Assuming end of data.\"\n            )\n            break  # Stop if no data or unexpected format\n\n        result = page_data if result is None else result\n        features_on_page = page_data.get(\"features\", [])\n        if not features_on_page:\n            logger.debug(\n                f\"No more features found for '{typeNames}' at startIndex {start_index}. Download likely complete.\"\n            )\n            break  # No features on this page, assume end of data\n        all_features.extend(features_on_page)\n        logger.debug(\n            f\"Fetched {len(features_on_page)} features for '{typeNames}'. Total fetched so far: {len(all_features)}.\"\n        )\n        # Stop if this page had fewer features than requested (indicates last page)\n        if len(features_on_page) &lt; page_count:\n            logger.debug(\n                f\"Last page fetched for '{typeNames}' (received {len(features_on_page)} features, requested up to {page_count}).\"\n            )\n            break\n        # Stop if max count is set and reached\n        if count is not None and len(all_features) &gt;= count:\n            logger.debug(\n                f\"Reached maximum count of {count} features for '{typeNames}'. Stopping download.\"\n            )\n            break\n\n        start_index += page_count\n\n    result[\"features\"] = all_features\n\n    # LINZ api seems to always return totalFeatures as \"unknown\" in the response\n    # So here we manually set it to the number of features we have\n    result[\"totalFeatures\"] = len(all_features)\n    # remove numberReturned because it relates to the last page, not the total\n    result.pop(\"numberReturned\", None)\n\n    logger.debug(\n        f\"Finished WFS data download for '{typeNames}'. Total features retrieved: {len(all_features)}.\"\n    )\n    return result\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.export.KExportError","title":"<code>KExportError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for errors encountered during export operations.</p> Source code in <code>src\\pykaahma_linz\\features\\export.py</code> <pre><code>class KExportError(Exception):\n    \"\"\"Custom exception for errors encountered during export operations.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.export.request_export","title":"<code>request_export(api_url, api_key, id, data_type, kind, export_format, crs=None, extent=None, **kwargs)</code>","text":"<p>Requests an export of a given item from the Koordinates API.</p> <p>Parameters:</p> Name Type Description Default <code>api_url</code> <code>str</code> <p>The base URL of the Koordinates API.</p> required <code>api_key</code> <code>str</code> <p>The API key for authentication.</p> required <code>id</code> <code>str</code> <p>The ID of the item to export.</p> required <code>data_type</code> <code>str</code> <p>The type of data ('layer' or 'table').</p> required <code>kind</code> <code>str</code> <p>The kind of export (e.g., 'shp', 'geojson').</p> required <code>export_format</code> <code>str</code> <p>The format for the export.</p> required <code>crs</code> <code>str</code> <p>Coordinate Reference System, if applicable.</p> <code>None</code> <code>extent</code> <code>dict</code> <p>Spatial extent for the export.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The response from the export request, typically containing job details.</p> <p>Raises:</p> Type Description <code>KExportError</code> <p>If the export request fails or if the response cannot be parsed.</p> <code>ValueError</code> <p>If the data type is unsupported or not implemented.</p> Source code in <code>src\\pykaahma_linz\\features\\export.py</code> <pre><code>def request_export(\n    api_url: str,\n    api_key: str,\n    id: str,\n    data_type: str,\n    kind: str,\n    export_format: str,\n    crs: str = None,\n    extent: dict = None,\n    **kwargs: Any,\n) -&gt; dict:\n    \"\"\"\n    Requests an export of a given item from the Koordinates API.\n\n    Parameters:\n        api_url (str): The base URL of the Koordinates API.\n        api_key (str): The API key for authentication.\n        id (str): The ID of the item to export.\n        data_type (str): The type of data ('layer' or 'table').\n        kind (str): The kind of export (e.g., 'shp', 'geojson').\n        export_format (str): The format for the export.\n        crs (str, optional): Coordinate Reference System, if applicable.\n        extent (dict, optional): Spatial extent for the export.\n        **kwargs: Additional parameters for the export.\n\n    Returns:\n        dict: The response from the export request, typically containing job details.\n\n    Raises:\n        KExportError: If the export request fails or if the response cannot be parsed.\n        ValueError: If the data type is unsupported or not implemented.\n    \"\"\"\n\n    logger.info(\"Requesting export\")\n\n    api_url = _ensure_ending_slash(api_url)\n    export_url = f\"{api_url}exports/\"\n    if data_type == \"layer\":\n        download_url = f\"{api_url}layers/\"\n    elif data_type == \"table\":\n        download_url = f\"{api_url}tables/\"\n    else:\n        raise ValueError(f\"Unsupported or not implemented data type: {data_type}\")\n    logger.debug(f\"{download_url=}\")\n\n    data = {\n        \"items\": [{\"item\": f\"{download_url}{id}/\"}],\n        \"formats\": {f\"{kind}\": export_format},\n        **kwargs,\n    }\n\n    if data_type == \"layer\" and crs:\n        data[\"crs\"] = crs\n    if data_type == \"layer\" and extent:\n        data[\"extent\"] = extent\n\n    logger.debug(f\"{data=}\")\n\n    headers = {\"Authorization\": f\"key {api_key}\"}\n\n    request_datetime = datetime.utcnow().isoformat()\n    try:\n        response = requests.post(export_url, headers=headers, json=data)\n        response.raise_for_status()\n        try:\n            json_response = response.json()\n        except ValueError as e:\n            err = f\"Error parsing JSON from export request: {e}\"\n            logger.debug(err)\n            raise KExportError(err)\n    except requests.exceptions.HTTPError as e:\n        err = f\"Failed export request with status code: {response.status_code}\"\n        logger.debug(err)\n        logger.debug(e)\n        raise KExportError(err)\n    return json_response\n</code></pre>"},{"location":"reference/#pykaahma_linz.features.export.validate_export_params","title":"<code>validate_export_params(api_url, api_key, id, data_type, kind, export_format, crs=None, extent=None, **kwargs)</code>","text":"<p>Validates export parameters for a given item.</p> <p>Parameters:</p> Name Type Description Default <code>api_url</code> <code>str</code> <p>The base URL of the Koordinates API.</p> required <code>api_key</code> <code>str</code> <p>The API key for authentication.</p> required <code>id</code> <code>str</code> <p>The ID of the item to export.</p> required <code>data_type</code> <code>str</code> <p>The type of data ('layer' or 'table').</p> required <code>kind</code> <code>str</code> <p>The kind of export (e.g., 'shp', 'geojson').</p> required <code>export_format</code> <code>str</code> <p>The format for the export.</p> required <code>crs</code> <code>str</code> <p>Coordinate Reference System, if applicable.</p> <code>None</code> <code>extent</code> <code>dict</code> <p>Spatial extent for the export.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters for the export.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the export parameters are valid, False otherwise.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the data type is unsupported or not implemented.</p> Source code in <code>src\\pykaahma_linz\\features\\export.py</code> <pre><code>def validate_export_params(\n    api_url: str,\n    api_key: str,\n    id: str,\n    data_type: str,\n    kind: str,\n    export_format: str,\n    crs: str = None,\n    extent: dict = None,\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"\n    Validates export parameters for a given item.\n\n    Parameters:\n        api_url (str): The base URL of the Koordinates API.\n        api_key (str): The API key for authentication.\n        id (str): The ID of the item to export.\n        data_type (str): The type of data ('layer' or 'table').\n        kind (str): The kind of export (e.g., 'shp', 'geojson').\n        export_format (str): The format for the export.\n        crs (str, optional): Coordinate Reference System, if applicable.\n        extent (dict, optional): Spatial extent for the export.\n        **kwargs: Additional parameters for the export.\n\n    Returns:\n        bool: True if the export parameters are valid, False otherwise.\n\n    Raises:\n        ValueError: If the data type is unsupported or not implemented.\n    \"\"\"\n\n\n    # validation_url = f\"{requests_url}validate/\"\n    logger.info(\"Validating export parameters\")\n    logger.info(data_type)\n\n    api_url = _ensure_ending_slash(api_url)\n    if data_type == \"layer\":\n        download_url = f\"{api_url}layers/\"\n    elif data_type == \"table\":\n        download_url = f\"{api_url}tables/\"\n    else:\n        raise ValueError(f\"Unsupported or not implemented data type: {data_type}\")\n    validation_url = f\"{api_url}exports/validate/\"\n\n    logger.debug(f\"{download_url=}\")\n\n    data = {\n        \"items\": [{\"item\": f\"{download_url}{id}/\"}],\n        \"formats\": {f\"{kind}\": export_format},\n        **kwargs,\n    }\n\n    if data_type == \"layer\" and crs:\n        data[\"crs\"] = crs\n    if data_type == \"layer\" and extent:\n        data[\"extent\"] = extent\n\n    logger.debug(f\"{data=}\")\n\n    headers = {\"Authorization\": f\"key {api_key}\"}\n    is_valid = False\n\n    try:\n        response = requests.post(validation_url, headers=headers, json=data)\n        response.raise_for_status()\n\n        # if response has any 200 status code, check for validation errors\n        if response.status_code in (200, 201, \"200\", \"201\"):\n            try:\n                json_response = response.json()\n                if any(\n                    not item.get(\"is_valid\", \"true\") for item in json_response[\"items\"]\n                ):\n                    err = \"An error occured when attempting to validate an export with this configuration. Check for 'invalid_reasons' in the logs.\"\n                    logger.error(err)\n                    logger.error(json_response[\"items\"])\n                    raise ValueError(err)\n                is_valid = True\n            except ValueError as e:\n                err = f\"Error parsing JSON from export validation: {e}\"\n                logger.debug(err)\n                raise ValueError(err)\n\n    except requests.exceptions.HTTPError as e:\n        status = e.response.status_code if e.response is not None else None\n        logger.error(\n            f\"HTTP error during validation: {status} - {getattr(e.response, 'text', '')}\"\n        )\n        if 400 &lt;= status &lt; 500:\n            raise ValueError(\n                f\"Bad request ({status}) for URL {validation_url}: {getattr(e.response, 'text', '')}\"\n            ) from e\n        raise\n\n    logger.debug(f\"Export parameters passed validation check. {is_valid=}\")\n    return is_valid\n</code></pre>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide walks you through the main ways to use the <code>pykaahma-linz</code> package to query and download data from the LINZ Data Service via Koordinates.</p>"},{"location":"usage/#connecting-to-the-linz-data-service","title":"Connecting to the LINZ Data Service","text":"<pre><code>from pykaahma_linz.KServer import KServer\nlinz = KServer(api_key=\"your-api-key\")\n</code></pre>"},{"location":"usage/#get-a-reference-to-an-item","title":"Get a reference to an item","text":"<p>For this snippet to work, create a .env file in the project root folder and include a variable called 'LINZ_API_KEY'.  </p> <pre><code>from dotenv import load_dotenv, find_dotenv\nfrom pykaahma_linz import KServer\ndotenv_path = find_dotenv()\nload_dotenv(dotenv_path)\napi_key = os.getenv('LINZ_API_KEY')\n\n#create server object\nlinz = KServer.KServer(api_key)\n\n#get item object\nrail_station_layer_id = \"50318\" #rail station 175 points\nitm = linz.content.get(rail_station_layer_id)\n#print item title\nprint(itm.title)\n</code></pre>"},{"location":"usage/#query-an-item-using-wfs-endpoint","title":"Query an item using WFS endpoint","text":"<p>Get all data  </p> <pre><code>data = itm.query()\n</code></pre> <p>Get first 5 records. Could be any records as there doesn't appear to be a sort argument, so probably only useful for data exploration.  </p> <pre><code>data = itm.query(count=5)\n</code></pre> <p>Data is returned as a geopandas GeoDataFrame, typed by the fields provided by the API.  </p> <pre><code>print(data.dtypes())\nprint(data.head())\n</code></pre>"},{"location":"usage/#get-a-changeset-using-wfs-endpoint","title":"Get a changeset using WFS endpoint","text":"<p>Also returned as a GeoDataFrame.</p> <pre><code>changeset = itm.get_changeset(from_time=\"2024-01-01T00:00:00Z\")\nprint((f\"Total records returned {itm.title}: {changeset.shape[0]}\"))\n</code></pre>"},{"location":"usage/#generate-an-export","title":"Generate an export","text":"<pre><code>job = itm.export(\"geodatabase\", crs=\"EPSG:2193\",)\nprint(job.status)\n</code></pre> <p>Download the job data once it is ready. If this method is called before the job is complete, it will keep polling the status of the job until it is ready and then downloads it.  </p> <pre><code>job.download(folder=r\"c:/temp\")\n</code></pre>"},{"location":"usage/#generate-an-export-with-extent-geometry","title":"Generate an export with extent geometry","text":"<pre><code>waikato_polygon = {\n        \"coordinates\": [\n          [\n            [\n              174.30400216373914,\n              -36.87399457472202\n            ],\n            [\n              174.30400216373914,\n              -38.83764306196984\n            ],\n            [\n              176.83017911725346,\n              -38.83764306196984\n            ],\n            [\n              176.83017911725346,\n              -36.87399457472202\n            ],\n            [\n              174.30400216373914,\n              -36.87399457472202\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n\njob = itm.export(\"geodatabase\", crs=\"EPSG:2193\", extent=waikato_polygon,)\nprint(job.status)\n</code></pre>"},{"location":"usage/#export-two-items-synchronously","title":"Export two items synchronously","text":"<p>This is just an expanded example of above, doing two items, one at a time.</p> <pre><code>def run_export_sync(itm, export_format, crs, output_folder):\n    job = itm.export(export_format, crs=crs)\n    print(f\"Started export job {job.id}\")\n    file_path = job.download(output_folder)\n    print(f\"{job.id} downloaded to {file_path}\")\n    return file_path\n\ndef export_multiple_items_sync():\n    output_folder = r\"c:\\temp\\data\\sync\"\n\n    logging.info(\"Starting multiple export jobs synchronously...\")\n    start_time = time.time()\n    result1 = run_export_sync(itm, \"geodatabase\", \"EPSG:2193\", output_folder)\n    result2 = run_export_sync(itm2, \"geodatabase\", \"EPSG:2193\", output_folder)\n    end_time = time.time()\n    logging.info(f\"Both export jobs completed in {end_time - start_time:.2f} seconds\")\n\n    print(f\"Both exports completed: {str([result1, result2])}\")\n\n# Call main_sync() in a normal script or notebook cell\nexport_multiple_items_sync()\n</code></pre>"},{"location":"usage/#export-two-items-asynchronously","title":"Export two items asynchronously","text":"<p>This is to contrast the synchronous example, and shows how two jobs could be initiated and downloaded asynchonously.  </p> <p>The alternative could be just to initiate two jobs seperately, and then write your own logic to poll both every few seconds and download as soon as one is ready.  </p> <pre><code>def run_export_sync(itm, export_format, crs, output_folder):\n    job = itm.export(export_format, crs=crs)\n    print(f\"Started export job {job.id}\")\n    file_path = job.download(output_folder)\n    print(f\"{job.id} downloaded to {file_path}\")\n    return file_path\n\ndef export_multiple_items_sync():\n    output_folder = r\"c:\\temp\\data\\sync\"\n\n    logging.info(\"Starting multiple export jobs synchronously...\")\n    start_time = time.time()\n    result1 = run_export_sync(itm, \"geodatabase\", \"EPSG:2193\", output_folder)\n    result2 = run_export_sync(itm2, \"geodatabase\", \"EPSG:2193\", output_folder)\n    end_time = time.time()\n    logging.info(f\"Both export jobs completed in {end_time - start_time:.2f} seconds\")\n\n    print(f\"Both exports completed: {str([result1, result2])}\")\n\n# Call main_sync() in a normal script or notebook cell\nexport_multiple_items_sync()\n</code></pre>"},{"location":"usage/#tests","title":"Tests","text":"<p>To run all tests:  </p> <p>To run all tests with logging. Leave off the log parameter if not wanting logging.  </p> <pre><code>uv run -m pytest --log-cli-level=INFO\n</code></pre> <p>To run a specific test, replace the relevant file name and test function.  </p> <pre><code>uv run -m pytest tests/test_simple.py::test_validate_layer_export_params --log-cli-level=INFO\n</code></pre>"}]}